[ { "title": "Usando Trivy en Gitea Actions. Escaneo de vulnerabilidades con herramientas de código abierto.", "url": "/posts/usando-trivy-en-gitea-actions/", "categories": "Seguridad Informática", "tags": "github, git, gitea, cicd", "date": "2023-12-12 16:31:00 +0100", "snippet": " Esta entrada cuenta con un TL;DRVoy a explicar como implementar Trivy en el CI/CD de Gitea. Si no sabes muy bien alguno de esos puntos lo explicaré a continuación, si no, puedes bajar directament...", "content": " Esta entrada cuenta con un TL;DRVoy a explicar como implementar Trivy en el CI/CD de Gitea. Si no sabes muy bien alguno de esos puntos lo explicaré a continuación, si no, puedes bajar directamente al apartado de implementación.Qué es CI/CDCI/CD viene de las siglas Continuous Integration/Continuous Delivery o Implementación Contínua/Despliegue Contínuo y viene siendo, a grandes rasgos, automatizar cosas durante el desarrollo de código. Estos son los puntos clave: Automatización de compilación y testeo: Automáticamente, con cada cambio en el repositorio git, se compila el nuevo código y se realizan pruebas para detectar fallos de forma temprana. Reportes intantáneos: Si algún test falla, se reporta automáticamente para que se pueda solucionar lo antes posible. Asegurar la calidad del código: Los entornos de desarrollo pueden tener definidas ciertas políticas, estándares, buenas prácticas… básicamente, unas normas. Puede velar por el cumplimiento de las buenas prácticas de la empresa. Despliegues automáticos en producción: A cada cambio en el repositorio y tras pasar las pruebas, se puede automatizar el despliegue en los servidores de producción, evitando así tener que hacerlo manualmente.En resumidas cuentas, gracias al CI/CD se reduce el tiempo de despliegue, el error humano y se flexibilizan y estandarizan los procesos de prueba y despliegue. Igulamente, intentaré dedicar una entrada a parte a explicar la metodología DevOps y DevSecOps, aunque Internet ya esté plagado de ellas.Automatizaciones de seguridad por CI/CDLos CI/CD pueden aprovecharse para automatizar ciertos controles de seguridad como vigilar los principales riesgos de las aplicaciones web con el OWASP Top 10 (SQLi, XSS, pérdidas de control de acceso…), avisar de incumplimientos de las políticas de seguridad de código, dependencias vulnerables, contenedores desactualizados, código malicioso ofuscado y todo lo que se te ocurra. Las posibilidades son enormes. Por ejemplo, abrir una issue si detecta secretos en el último commit, bloquear un pull requests a master si una llamada permite una inyección SQL o mandar un correo si hay que actualizar la imagen docker que se usa como base.Introduciendo Trivy, el escáner de seguridad de código abiertoAhora bien, toda esta magia debe hacerse con las herramientas adecuadas. Soy consciente que la mayoría de estas implementaciones solo son viables en entornos empresariales y no en proyectos de prueba que a las 3 semanas quedan en el olvido (a no ser que seas un rarito de la seguridad como yo que gasta más tiempo trasteando con estas cosas que en el propio proyecto).Una herramienta con la que he tenido buenos resultados, es sencilla y es de código libre es Trivy, un escaner de seguridad de código libre creado por Aqua Security. En esta entrada veremos como integrarlo en un CI/CD para escanear el código de un repositorio git y la última imagen docker creada en base a este, pero también es posible usarlo para detectar vulnerabilidades en dependencias de código o de sistemas, fallos en IaaC, Kubernetes y alguna cosa más. También puede usarse vía CLI para lanzarlo manualmente mientras se escribe código o se compila una imagen en local.Introduciendo Gitea Actions, un GitHub ligero y abiertoAunque sigo teniendo GitHub para cosas puntuales, desde hace más de un año que llevo usando Gitea como mi servidor git remoto, en él tengo mi propia organización, repositorios propios públicos y privados, mis imágenes docker personalizadas y, por supuesto, mis pipelines.Creando un Gitea Action El Gitea Actions es compatible con GitHub Actions, si hiciera falta alguna modificación, se avisa en el texto. Primero vamos a crear el archivo YAML que Gitea detectará automáticamente para ejecutar el workflow, este será en .gitea/workflows/security.yml. Si es para GitHub, debe estar en el directorio .github/workflows/. Ahora, en el archivo, definimos el nombre de la acción y cuando se ejecutará, en este ejercicio haremos que se lance todos los días 15 a las 4AM. name: Security Scan on: schedule: - cron: \"0 4 15 * *\" Añadimos el espacio de trabajo desde el que se ejecutará todo: jobs: scan: runs-on: ubuntu-latest container: image: catthehacker/ubuntu:act-latest # Ubuntu image compatible with nektos/act, the gitea action runner Dentro, añadimos un punto para obtener el último commit y otro para sacar el nombre del repositorio: steps: - name: Checkout uses: actions/checkout@v3 with: fetch-depth: 0 - name: Get Meta id: meta run: | echo REPO_NAME=$(echo ${GITHUB_REPOSITORY} | awk -F\"/\" '{print $2}') &gt;&gt; $GITHUB_OUTPUT Ahora hacemos el escaneo de la última imagen usando el paso de trivy. Como parámetros le indicaremos que nos muestre únicamente las vulnerabilidades corregidas, en una tabla, que nos vuelque todo a un archivo, y que el código de error sea siempre 0. - name: Image Scan uses: aquasecurity/trivy-action@master with: image-ref: 'gitea.host.tld/user-or-org-name/${{ steps.meta.outputs.REPO_NAME }}:latest' format: 'table' exit-code: '0' ignore-unfixed: true vuln-type: 'os,library' output: 'image-scan.txt' Hacemos lo mismo con el escaneo en el propio repositorio. Como ya lo hemos descargado en el paso 4, usamos la opción fs (filesystem). - name: Code Scan uses: aquasecurity/trivy-action@master with: scan-type: 'fs' ignore-unfixed: true format: 'table' output: 'code-scan.txt' exit-code: '0' Este último paso sí que difiere. En GitHub existe un paso creado por la comunidad para subir issues al proyecto. Como en Gitea no es posible, usaremos la API para publicar el contenido de ambos ficheros. - name: Create Issue env: API_TOKEN: ${{ secrets.ORG_ISSUES_TOKEN }} run: | ISSUE_TITLE=\"Security report $(date +'%d/%m/%Y')\" ISSUE_CONTENT=$(cat 'image-scan.txt' 'code-scan.txt') curl -X POST -H \"Authorization: token ${API_TOKEN}\" -H \"Content-Type: application/json\" \\ -d \"{\\\"title\\\": \\\"$ISSUE_TITLE\\\", \\\"body\\\": \\\"$ISSUE_CONTENT\\\"}\" \\ https://gitea.host.tld/api/v1/repos/user-or-org-name/${{ steps.meta.outputs.REPO_NAME }}/issues Podemos guardar el archivo, pero no hemos terminado. En el último paso, podemos ver que hemos definido la variable API_TOKEN y hace referencia a ${{ secrets.ORG_ISSUES_TOKEN }}. Este es un secreto que solo el CI puede consultar. Pero claro, primero debemos crearlo.Definiendo el secretoEl secreto va a ser un API Token para publicar issues. Siguiendo la política de privilegio mínimo, vamos a crear uno únicamente con este fin. Accedemos a la configuración del usuario y en Aplicaciones podremos crear el token de escritura en las issues.Ahora toca copiar el token resultante y definirlo como secreto en los Ajustes de usuario &gt; Acciones &gt; Secretos. Para esta ocasión, y como el token se va a usar en otros proyectos, lo definiré a nivel de organización desde la Configuración de la organización &gt; Acciones &gt; Secretos.Como el proyecto desde el que se ejecuta el workflow es parte de la organización, el secreto se puede consultar durante la ejecución.ComprobaciónCuando llegue el momento, el CI ejecutará el workflow y lanzará el escaneo de seguridad como hemos definido.Y veremos como el usuario del API Token ha creado un issue con una tabla bastante amorfa (pero entendible) con los resultados.Como punto de mejora, podemos hacer que Trivy nos devuelva los resultados en formato JSON y, luego, nosotros lo parseamos a una tabla Markdown más aseada o en el formato que deseemos.TL;DR Crear un secreto con el API Token para crear issues en el proyecto. Llamarlo ORG_ISSUES_TOKEN y guardarlo en el proyecto o la organización. Usamos este código como workflow: name: Security Scan on: schedule: - cron: \"0 4 15 * *\" jobs: scan: runs-on: ubuntu-latest container: image: catthehacker/ubuntu:act-latest # Ubuntu image compatible with nektos/act, the gitea action runner steps: - name: Checkout uses: actions/checkout@v3 with: fetch-depth: 0 - name: Get Meta id: meta run: | echo REPO_NAME=$(echo ${GITHUB_REPOSITORY} | awk -F\"/\" '{print $2}') &gt;&gt; $GITHUB_OUTPUT echo REPO_VERSION=$(git describe --tags --always | sed 's/^v//') &gt;&gt; $GITHUB_OUTPUT - name: Image Scan uses: aquasecurity/trivy-action@master with: image-ref: 'gitea.host.tld/user-or-org-name/${{ steps.meta.outputs.REPO_NAME }}:latest' format: 'table' exit-code: '0' ignore-unfixed: true vuln-type: 'os,library' output: 'image-scan.txt' - name: Code Scan uses: aquasecurity/trivy-action@master with: scan-type: 'fs' ignore-unfixed: true format: 'table' output: 'code-scan.txt' exit-code: '0' - name: Create Issue env: API_TOKEN: ${{ secrets.ORG_ISSUES_TOKEN }} run: | ISSUE_TITLE=\"Security report $(date +'%d/%m/%Y')\" ISSUE_CONTENT=$(cat 'image-scan.txt' 'code-scan.txt') curl -X POST -H \"Authorization: token ${API_TOKEN}\" -H \"Content-Type: application/json\" \\ -d \"{\\\"title\\\": \\\"$ISSUE_TITLE\\\", \\\"body\\\": \\\"$ISSUE_CONTENT\\\"}\" \\ https://gitea.host.tld/api/v1/repos/user-or-org-name/${{ steps.meta.outputs.REPO_NAME }}/issues " }, { "title": "Proteger las cabeceras HTTP con Cloudflare, Traefik, Apache y Nginx", "url": "/posts/proteger-headers-con-cloudflare/", "categories": "Seguridad Informática", "tags": "cloudflare, http, headers", "date": "2023-01-08 11:37:54 +0100", "snippet": "Los servicios web expuestos son una causa frecuente de intentos de ataque. El uso de exploits, XSS, inyecciones SQL, páginas mal protegidas, robo de cookies… En fin, es importante proteger estos pu...", "content": "Los servicios web expuestos son una causa frecuente de intentos de ataque. El uso de exploits, XSS, inyecciones SQL, páginas mal protegidas, robo de cookies… En fin, es importante proteger estos puntos de acceso a nuestros sistemas. A nivel programático deben gestionarse bien los sistemas de autenticación, páginas protegidas y posibles inyecciones, pero nosotros, como administradores de los sistemas, también podemos y debemos reducir estos riesgos.Las cabeceras HTTP, o headers, envían información entre el cliente y servidor. Por parte del cliente, puede mandar datos como su navegador, sistema operativo o una cookie de sesión. El servidor generalmente utiliza los headers para indicarle al navegador qué JS o CSS puede ejecutar, el tipo de servidor y la versión de este, entre otras cosas.Headers de seguridadLos servidores web deben configurarse para mandar ciertas cabeceras y protegerse a sí mismos y a los clientes de posibles ataques. Puedes saber qué headers envía tu servidor empleando páginas como https://securityheaders.com.Esta página te muestra las cabeceras inseguras, qué implican y cómo solventarlas. Nosotros vamos a hacer una planificación con una seguridad base generalista. Referrer-Policy: Indica si el navegador debe mostrar la página de origen al hacer clic a un enlace. Se usa principalmente para analíticas pero puede haber páginas que requieran de esta función. Permissions-Policy: Es la nueva versión del Feature-Policy, solo cambia el nombre. Esta cabecera le dice al navegador qué permisos pueden solicitar las páginas. De esta forma, si un servidor es vulnerado y el atacante intenta solicitar permisos de cámara y micrófono del navegador del cliente, esta header puede evitar que lo logre. Content-Security-Policy: Hace referencia a los JS y CSS que se permiten ejecutar. Limita el protocolo y la ubicación de su procedencia. Por ejemplo, puede hacer que no se permita la ejecución de JavaScript externo a la propia página y que siempre deba ir por HTTPS. X-Content-Type-Options: Evita que los navegadores acepten cualquier tipo de contenido y fuerzas el uso de los MIME declarados por le servidor. Solo tiene el valor nosniff. X-Frame-Options: Restringe que el servidor pueda ser añadido como iframe en una página fraudulenta. Evita ataques de clickjacking. server: Muestra el servidor web y su versión. Puede ser peligroso porque puede existir una vulnerabilidad conocida para ese servidor, debe modificarse por otro valor. Strict-Transport-Security: Fuerza el uso de TLS en la conexión. El navegador guarda esta header y no permitirá la conexión con la web si deja de usar TLS. La cantidad de tiempo que permanecerá el valor guardado por le navegador se especifica como valor.Añadiendo estas cabeceras habremos aumentado enormemente la seguridad de nuestro servidor y de los clientes que lo visitan.Headers básicos de ejemploDebes leer la documentación y ver que headers van a ser necesarios y que política deben cumplir. Añadir una política demasiado restrictiva puede hacer que el sitio deje de funcionar correctamente. En este enlace se da una guía más detallada de qué opciones tiene cada header. Vamos a dar un ejemplo básico: Referrer-Policy: strict-origin-when-cross-origin: El navegador enviará la URL completa a las solicitudes con el mismo origen, pero solo enviará el origen cuando las solicitudes sean de orígenes externos. Permission-Policy: geolocation=(): El navegador solo permitirá que el servidor solicite permisos para la geolocalización. Content-Security-Policy: frame-ancestors 'self'; frame-src 'self' object-src 'self'; base-uri 'self': Permite los iframes que vienen de la propia página y de las páginas relacionadas con esta. Content-Security-Policy CheatSheet X-Content-Type-Options: nosniff: Es el único valor posible. X-Frame-Options: SAMEORIGIN: Solo permite iframes del mismo servidor. server: Yes: Se puede poner cualquier valor siempre y cuando no de información sobre el servidor. Strict-Transport-Security: max-age=31536000; includeSubDomains: Fuerza el uso de TLS para el dominio y subdominios durante un año.Implementar headersAhora que tenemos nuestras cabeceras de seguridad según nuestras necesidades, es hora de implementarlas. Dependiendo de la infraestructura que tengamos usaremos una herramienta u otra. Los headers pueden ponerse en los propios servidores web (Apache y Nginx) o en servicios de proxy inverso (Traefik y Cloudflare).Headers en CloudflarePuedes modificar los headers en Cloudflare independientemente de si tu cuenta es gratuita o de pago. Con la gratuita tienes un máximo de 10 transformaciones pero puedes usar un para modificar todas las cabeceras que quieras. Si quieres añadir filtros para que solo se apliquen a ciertas páginas entonces sí que tendrás que gastar el resto de transformaciones.Las transformaciones puedes encontrarlas en Rules &gt; Transform Rules &gt; HTTP Response Header Modification.Headers en TraefikSi usas las labels de los contenedores Docker para exponer tus servicios estás de suerte, las cabeceras también pueden editarse individualmente para cada servicio usando esta herramienta. Un ejemplo sencillo sería el siguiente:labels: - \"traefik.http.middlewares.&lt;Nombre_del_servicio&gt;.headers.customresponseheaders.X-Frame-Options=SAMEORIGIN\"Si, por otro lado, prefieres editar directamente el archivo YAML de configuración de Traefik puede hacerse añadiendo lo siguiente:http: middlewares: &lt;Nombre_del_servicio&gt;: headers: customResponseHeaders: X-Frame-Options: \"SAMEORIGIN\"He de decir que solo he probado la primera opción. Para implementarlo en Kubernetes, Rancher, Marathon o configurarlo usando el TOML de Traefik, toda la documentación oficial se encuentra en este enlaceHeaders en ApacheSi queremos configurar los headers en Apache primero debemos activar el módulo correspondiente.sudo a2enmod headersAhora se edita el fichero de configuración del sitio al que le queremos añadir los headers, usualmente en /etc/apache2/sites-enabled/archivo_configuración.conf, añadimos una línea por cada cabecera, tienen la siguiente estructura. Documentación oficial con las opciones de la directiva HeaderHeader always set X-Frame-Options \"SAMEORIGIN\"Recordar que hay que reiniciar el servidor tras estos cambios.sudo systemctl restart apache2Headers en NginxDentro del archivo de configuración de Nginx en /etc/nginx/nginx.conf se pueden añadir líneas para añadir, eliminar y modificar headers. Aquí un ejemplo.add_header X-Frame-Options SAMEORIGIN;Tras esto, hay que reiniciar el servicio.sudo systemctl restart nginx" }, { "title": "Usando la clave privada GPG de Yubikey en un nuevo ordenador", "url": "/posts/a%C3%B1adiendo-clave-privada-yubikey-nuevo-ordenador/", "categories": "Misceláneo", "tags": "gpg, linux, pgp, yubico, yubikey, git, github", "date": "2022-12-18 17:47:07 +0100", "snippet": "Supongamos que hemos seguido los pasos para crear y añadir claves GPG a YubiKey en un ordenador y nos ha ido todo bien. Las claves y subclaves privadas están almacenadas en nuestro dispositivo y po...", "content": "Supongamos que hemos seguido los pasos para crear y añadir claves GPG a YubiKey en un ordenador y nos ha ido todo bien. Las claves y subclaves privadas están almacenadas en nuestro dispositivo y podemos comprobarlo con un gpg -K./Users/ockham/.gnupg/secring.gpg------------------------------------sec&gt; 4096R/3AA5C34371567BD2 2022-03-08 [SC] [caduca: 2022-09-04] Número de serie de la tarjeta = 0006 16752384uid [ absoluta ] Ockham Odyssey &lt;admin@odiseageek.es&gt;ssb&gt; 4096R/42B317FD4BA89E7A 2022-03-08 [A] [caduca: 2022-09-04]ssb&gt; 4096R/44BF8217A52AF753 2022-03-08 [E] [caduca: 2022-09-04]Ya sabemos que el símbolo &gt; significa que esas claves se encuentran en la Yubikey pero, ¿qué pasa si queremos usar las claves en un nuevo ordenador? Aunque conectemos la llave no nos aparecerán las claves. Para solucionarlo solo hay que lanzar unos pocos comandos.Primero hay que comprobar si tenemos nuestra clave pública.gpg -kSi no tenemos la clave pública no podemos continuar. La clave púbica la obtendremos de un servidor de claves o del anterior ordenador.Una vez tengamos la clave pública en nuestro ordenador, podemos usar el comando gpg --card-status para ver la vinculación de la clave privada de la Yubikey con la clave pública que tenemos en nuestro llavero.General key info..: pub rsa2048/61D4104EAD00CCE7 2022-03-10 Ockham Odyssey &lt;admin@odiseageek.es&gt;sec&gt; rsa2048/61D4104EAD00CCE7 creado: 2022-03-10 caduca: 2022-09-04 num. tarjeta: 0006 16686462ssb&gt; rsa2048/A727D9E9D662D0F4 creado: 2022-03-10 caduca: 2022-09-04 num. tarjeta: 0006 16686462ssb&gt; rsa2048/603701C9D96673AA creado: 2022-03-10 caduca: 2022-09-04 num. tarjeta: 0006 16686462Si en General key info vemos un [ none ] es que la clave pública que hemos pasado no es la correcta.Cuando veamos algo parecido a lo de arriba, entramos en las opciones de la llave con gpg --card-edit y escribimos el comando fetch. Esto añadirá las claves GPG privadas a nuestro llavero. Salimos con de la terminal de GPG con un quit.Si ejecutamos de nuevo gpg -K veremos que ahora sí que aparecen las claves de nuestra Yubikey." }, { "title": "Usar Discord en Linux sin actualizar", "url": "/posts/usar-discord-en-linux-sin-actualizar/", "categories": "Misceláneo", "tags": "discord, linux, Arch Linux, AUR", "date": "2022-09-19 19:13:12 +0200", "snippet": " Esta entrada se ha probado en equipos basados en Debian y en Arch Linux a día 19/09/2022 y 05/09/2023 respectivamente.Es bien sabido que la atención que le da Discord a Linux es bastante justita:...", "content": " Esta entrada se ha probado en equipos basados en Debian y en Arch Linux a día 19/09/2022 y 05/09/2023 respectivamente.Es bien sabido que la atención que le da Discord a Linux es bastante justita: sin compatibilidad con Wayland, problemas de audio al compartir ventana en XOrg y la falta de repositorios. Aún así, se agradece poder tener un .deb en la página oficial. Nadie sabe el porqué de esta falta de interés, las aplicaciones nativas de Discord están basadas en Electron, por lo que su gestión en todos los sistemas debería ser pan comido.Para los sistemas Arch o Red Hat, tener un .deb como único modo de instalación es casi como no tener nada. Y digo casi porque, al menos en Arch, tenemos el maravilloso AUR desde el que podemos actualizar Discord, aunque con algo de retraso.Mientras no tengas Discord actualizado te aparecerá un mensaje como el de la captura de arriba. Existe una forma de evitarlo en caso de no poder descargar o instalar la última versión. Solo tenemos que editar el archivo ~/.config/discord/settings.json añadiendo la línea \"SKIP_HOST_UPDATE\": true al final del JSON, muy importante esto. Un ejemplo del resultado:{ \"IS_MAXIMIZED\": true, \"IS_MINIMIZED\": false, \"WINDOW_BOUNDS\": { \"x\": 2240, \"y\": 219, \"width\": 1280, \"height\": 720 }, \"SKIP_HOST_UPDATE\": true}Tras estos cambios podemos volver a abrir Discord sin que nos solicite ninguna actualización." }, { "title": "Firmando commits con GPG y Yubikey", "url": "/posts/firmando-commits-con-gpg-y-yubikey/", "categories": "Misceláneo", "tags": "gpg, linux, pgp, yubico, yubikey, git, github", "date": "2022-08-01 18:51:55 +0200", "snippet": " En esta entrada no vamos a explicar cómo generar claves GPG para la Yubikey, para ello tenemos esta otra: Creando y añadiendo claves GPG a YubiKeyYa hemos visto en otras entradas el gran potencia...", "content": " En esta entrada no vamos a explicar cómo generar claves GPG para la Yubikey, para ello tenemos esta otra: Creando y añadiendo claves GPG a YubiKeyYa hemos visto en otras entradas el gran potencial que tienen las Yubikey. Esta ocasión va a ser algo de gran interés para aquellos desarrolladores que no paran de hacer commits en git. Vamos a usar la Yubikey para firmar todos los commits que hagamos. Según el servidor git, podremos hacer que, si no se han firmado, se marquen como “No validados”.Pasos previosPartiremos por la base del anterior post y asumiremos que ya tenemos todas nuestras claves generadas y guardadas en la llave. Por lo que, al conectar la Yubikey al ordenador y ejecutar la orden gpg -K nos debería devolver algo parecido a lo siguiente:/home/ockham/.gnupg/pubring.kbx-------------------------------sec&gt; rsa2048 2022-03-10 [SC] [caduca: 2022-09-04] B12F58499135721C09A1EEA261D4104EAD00CCE7uid [ absoluta ] Ockham Odyssey &lt;admin@odiseageek.es&gt;ssb&gt; rsa2048 2022-03-10 [E] [caduca: 2022-09-04]ssb&gt; rsa2048 2022-03-10 [A] [caduca: 2022-09-04]Si no es así, se tendrá que seguir la otra entrada del blog antes de continuar.Configurando gitPrimero de todo buscaremos nuestra clave privada:gpg --list-secret-keys --keyid-format=longRecibiremos una respuesta como la siguiente:/Users/ockham/.gnupg/secring.gpg------------------------------------sec&gt; 4096R/3AA5C34371567BD2 2022-03-08 [SC] [caduca: 2022-09-04] Número de serie de la tarjeta = 0006 16752384uid [ absoluta ] Ockham Odyssey &lt;admin@odiseageek.es&gt;ssb&gt; 4096R/42B317FD4BA89E7A 2022-03-08 [A] [caduca: 2022-09-04]ssb&gt; 4096R/44BF8217A52AF753 2022-03-08 [E] [caduca: 2022-09-04]Como buscamos firmar, seleccionaremos la primera clave (3AA5C34371567BD2) y ejecutaremos el siguiente comando para indicar a git que esa será nuestra clave de firma:git config --global user.signingkey 3AA5C34371567BD2Ahora configuraremos git para que firme todos los commits por defecto:git config --global commit.gpgsign trueY ya está. Ahora, a la hora de hacer un commit, según hayamos configurado la tarjeta, nos solicitará ciertos pasos. Si hemos seguido el orden del posts anterior, primero tendremos que dar la contraseña de la Yubikey para firmar y luego tendremos que pulsarla. El comando git se mantendrá a la espera de estos pasos para comenzar a firmar.Configurando GitHubSi queremos que GitHub tenga en cuenta nuestras firmas tendremos que ir a la configuración de claves SSH y GPG. Pegaremos la clave pública que podemos obtener tras ejecutar gpg --armor--export 3AA5C34371567BD2.ComprobaciónUna vez hayamos hecho un commit (podemos hacerlo sin el -S para firmar si hemos configurado que firme por defecto) podremos verificar que se ha firmado correctamente ejecutando la siguiente orden:git show HEAD --show-signatureTras hacer un push en GitHub, también podremos comprobar que reconoce la firma y marca el commit como verificado." }, { "title": "Software libre para mejorar en el estudio", "url": "/posts/software-libre-para-mejorar-en-el-estudio/", "categories": "Misceláneo", "tags": "estudio, linux", "date": "2022-04-15 21:27:21 +0200", "snippet": "Los exámenes finales han pasado hace poco y me gustaría aprovechar el momento para compartir las aplicaciones que más me han ayudado a mejorar a estudiar. Si no sabes qué es el software libre, se p...", "content": "Los exámenes finales han pasado hace poco y me gustaría aprovechar el momento para compartir las aplicaciones que más me han ayudado a mejorar a estudiar. Si no sabes qué es el software libre, se puede resumir en que son aquellos programas gratuitos y cuyo código está disponible al público para estudiarlo y modificarlo, por lo que es totalmente seguro y tienes todo el control de lo que usas.No hay fórmula mágicaSé que suena a tópico, pero es la verdad. Cada persona se organiza la cabeza de una forma distinta, es importante encontrar el método que a uno le funcione. Particularmente tardé varios años en encontrar mi método de estudio, hasta que una amiga me mostró el pomodoro y mi motivación subió por las nubes.Algunos se organizan con libretas, otros con una planificación por horas, con colores, con webs, en papel, en una pizarra, otros si se organizan es peor… Cada cual es un mundo. Por eso, después de leer esta publicación, te invito a seguir buscando sobre el tema para tener más ideas y probar las que mejor te parezcan.Aplicaciones libresHabiticaSin duda la aplicación por excelencia. Habitica transforma el crear hábitos en un juego de rol. Cumpliendo los objetivos diarios y periódicos haces daño a jefes y consigues experiencia con la que comprar objetos y obtener más bonus. En cambio, no cumplir con los objetivos restará vida a ti y a tus amigos. El sistema es simple y motivador y me ha ayudado a tener una checklist de las actividades pendientes de clase y de obligarme a revisar ciertas materias al menos una vez por semana.Por si fuera poco, Habitica no te “obliga” a nada. Todos los stats, rachas, vida, niveles, experiencia y más datos puedes cambiarlos a tu antojo. Sí, eso es hacer trampas, y haciendo eso la aplicación no tiene sentido, pero te dan la posibilidad de hacerlo o no, cualquiera puede tener un mal día. El ambiente que hay en la aplicación es genial y motivador. Una de las mejores cosas es que no se compite, no hay paytowin porque no hay quien gana y quien pierde, solo gente que se ayuda mutuamente y crean equipos para derrotar a los jefes.La flexibilidad de la aplicación también es tremenda. A medida que consigues monedas de oro, puedes gastarlas en mejorar tu equipamiento o puedes crear tus propios incentivos (como “saltarse la dieta cuesta 100 monedas”). Si empiezan las vacaciones y no vas a entrar durante ese tiempo, puedes mandar a tu personaje a la Taberna, donde dormirá hasta que vuelvas y, durante ese tiempo, no recibirá daño ni se romperán las rachas.Habitica es gratuita y de código libre. Tanto la página web como las aplicaciones para Android y iOS están gestionadas por los voluntarios y se mantiene a base de donaciones y las compras de gemas, la moneda “premium” con la que podrás obtener skins especiales.Super ProductivityMientras Habitica se centra en la organización de tareas y hábitos, el punto fuerte de Super Productivity es la ejecución. Nada más abrir la aplicación tenemos nos encontramos con las pestañas de “Hoy”, “Línea de Tiempo” y “Programado”. En estas tres pestañas se verán las tareas que tenemos planificadas y marcadas. Cuando se crea una tarea se le puede indicar el día y la hora a la que planeamos iniciarla, que subtareas tiene y cuánto tiempo le vamos a dedicar. Además, podemos ordenar las tareas por proyectos y etiquetas. La propia aplicación acepta integración con GitHub y, aunque se ha pedido, no se ha integrado aún con la API de Habitica, el programador voluntario que gestiona la aplicación ha dicho que se implementará si alguien decide ayudarle con esa parte.El punto fuerte de esta herramienta son las métricas. A medida que vamos trabajando la aplicación se guardará cuanto tiempo hemos invertido en cada tarea, los descansos que hemos hecho y más. También viene incorporado (de forma opcional) un temporizador pomodoro al que le podemos modificar el tiempo que queremos que duren las sesiones de descanso y de trabajo.Con todo esto, una vez terminemos el día, el programa nos pedirá que respondamos a algunas preguntas: cómo nos sentimos, si hemos sido productivos y qué creemos que podemos hacer para mejorar mañana, entre otras. El resultado de esta última pregunta, por ejemplo, nos aparecerá como recordatorio al día siguiente para que intentemos cumplirlo, un detallazo.Una vez acabemos el día podremos ver en qué hemos trabajado a lo largo de la semana, y gráficas con nuestra productividad según los datos que le hemos indicado en las respuestas.Esta aplicación también es gratuita y de código abierto. Está disponible como página web, aplicación de escritorio para Mac, Linux y Windows y aplicación móvil para Android. En ningún momento los datos salen de tu ordenador, ni siquiera en la aplicación web, todo se gestiona en tu ordenador y mediante cookies de navegador y se tiene la opción de sincronización con todos los dispositivos que quieras mediante un archivo que puedes guardar en tu Google Drive.BlanketComo toda aplicación de GNOME que se precie, Blanket es estúpidamente simple y, aun así, cumple perfectamente su cometido. Tal y como dice su descripción (porque el nombre no da muchas pistas), Blanket mejora la concentración y aumenta la productividad con diferentes sonidos ambiente.Sé que a no todo el mundo le va el tema de los sonidos ambientales, pero darles una oportunidad no hace daño. A diferencia de otros sitios, no he notado las repeticiones de los sonidos, está muy bien logrado. Entre otros tiene: aves, cafetería, chimenea, grillos, lluvia, olas, tren y viento. A demás puedes hacer mezclas, guardando perfiles con las combinaciones que más te gustan y ponerles un volumen distinto a cada sonido.Como toda aplicación de GNOME, es gratuita y libre. Se integra bien en el entorno de GNOME, pero se puede descargar en cualquier sistema GNU/Linux desde Flatpak o los repositorios oficiales.LanguageToolLa herramienta Grammarly es bastante conocida en la comunidad de habla inglesa. Te ayuda a realizar mejores textos analizando tus oraciones morfológica y sintácticamente, pero es privativa y solo está disponible en inglés. Pues bien, la alternativa LanguageTool no solo es de código libre, también está disponible en español, catalán, gallego, asturiano, portugués, polaco, alemán, francés, japonés y un largo, muy largo, etcétera.Cuenta con su propio editor en línea, ideal para redactar correos electrónicos o textos temporales. También cuenta con extensión para Word, LibreOffice (así se puede usar sin conexión a Internet), Google Docs, Overleaf y extensión para cualquier navegador y así usarlo dónde sea.Su uso es gratuito y ofrece un “modo perfeccionista” para aquellos que compren la versión premium, no muy necesaria para el uso habitual, pero que a mí me vendrá de perlas para el proyecto de fin de curso.MarkTextNo amé el Markdown hasta que no estaba ya hasta el cuello de exámenes, y me ha ayudado enormemente. Para aquellos que no lo conozcan, el lenguaje Markdown es una capa que se pone encima del HTML para poder hacer textos parecidos a un archivo Word sin escribir código ni tener que separar las manos del teclado. En este enlace os dejo otro artículo explicándolo un poco y dando ejemplos. Pero se puede resumir como el lenguaje ideal para apuntes, tiene la misma potencia que un doc de Word sin la desventaja de que se te destroza todo cuando mueves una imagen un milímetro.Puedes usar MarkText (en el momento de escribir esta entrada la página web de MarkText estaba caída, puedes acceder desde su repositorio de GitHub) como un editor de textos normal, pero usando la sintáxis de Markdown para que todos los textos tengan el formato que toca. También puedes utilizar el editor plano donde verás todo el código que escribes, ideal para esos momentos en los que tienes que poner fórmulas matemáticas, por ejemplo.Otro gran acierto es que soporta de forma nativa el uso de Mermaid, una herramienta para crear diagramas de Gantt, de entidad-relación, de flujo, secuencias y muchos más. Con un poquito más de código para escribir, eso sí, pero muy fácil una vez se le pilla el truco.Cabe decir que todo el texto que se pone, incluidas las flechas de los diagramas y las fórmulas matemáticas, se adaptan al modo oscuro o claro que pongas en la aplicación. Y luego puedes exportar el Markdown como PDF para verlo con claridad, añadiendo en las opciones de exportación si quieres cabeceras o pies de página.ConclusiónHerramientas no faltan. Una buena organización y un buen ambiente de estudio es ideal para ser eficiente. Yo he tenido la suerte de tener unas herramientas y unas amigas que me han ayudado a conseguir lo que creía imposible, que disfrute estudiando y eche de menos los momentos de exámenes finales que pasaba junto a ellas (quitando el maldito estrés). Por suerte mi época de estudios aún no ha terminado.Iré actualizando esta lista a medida que descubra más aplicaciones interesantes, sean libres o privativas. Y si alguien quiere aportar las suyas en los comentarios o mandándome un mensaje en Twitter estaré encantado." }, { "title": "Creando y añadiendo claves GPG a YubiKey", "url": "/posts/creando-y-anadiendo-claves-gpg-a-yubikey/", "categories": "Apuntes ASIR, Seguridad y Alta Disponibilidad", "tags": "gpg, linux, pgp, yubico, yubikey", "date": "2022-03-11 13:39:33 +0100", "snippet": "En esta publicación no vamos a entrar en detalles sobre qué es una YubiKey o una clave GPG, ni qué usos tienen, vamos a ir directos al grano. Pero explicando todos los procesos y lo que aparece en ...", "content": "En esta publicación no vamos a entrar en detalles sobre qué es una YubiKey o una clave GPG, ni qué usos tienen, vamos a ir directos al grano. Pero explicando todos los procesos y lo que aparece en pantalla. Igualmente, si hay cosas que no se entienden agradecería que aviséis en los comentarios para corregirlo.Primero de todo, las llaves YubiKey disponen de una contraseña de acceso y una de administración. La contraseña de administración se usa para añadir las claves, la de acceso para utilizarlas.PreparaciónPrimero de todo, vamos a asegurarnos que los paquetes que necesitamos están instalados:ccid: Es el driver de tarjetas inteligentes.gnupg o gpg: Normalmente, ya viene preinstalado en la mayoría de sistemas.yubikey-personalization: Para cambiar algunos parámetros de la llave.pinentry: Solicita las claves de la tarjeta para poder realizar la operación gpg.Además, necesitamos habilitar el demonio de las tarjetas inteligentes.sudo systemctl start pcscdsudo systemctl enable pcscdContraseñas en la YubiKeygpg --card-editCon el anterior comando estamos entrando en el módulo de claves GPG de la YubiKey, este módulo tiene su propio sistema de autentificación con contraseñas por defecto, por eso es muy importante cambiarlas. Primero, para poder realizar cambios cruciales en la tarjeta entraremos como administradores con el comando admin.gpg/tarjeta&gt; adminSe permiten órdenes de administrador Nombre Valor por defecto Uso PIN 123456 Acceso y uso de las claves GPG Admin PIN 12345678 Modificación de las claves GPG Reset PIN N/A Resetear PIN Nos interesa cambiar al menos las dos primeras. Para ello, en el prompt de la Yubikey, escribimos passwd. Nos devolverá algo parecido a esto:gpg/tarjeta&gt; passwdgpg: tarjeta OpenPGP num. D2760001240103040006166864620000 detectada1 - change PIN2 - unblock PIN3 - change Admin PIN4 - set the Reset CodeQ - quitSu elección: En nuestro caso usaremos la opción 1 y la opción 3Creación de las clavesAhora toca crear las claves. Para usar la YubiKey de la mejor forma generaremos un par de claves maestros, que nos servirán para firmar y certificar y del que colgarán dos subclaves, para encriptar y autenticar respectivamente.Si no lo hemos hecho ya, salimos del prompt de la tarjeta. Ahora escribimos el comando para generar las claves.gpg --full-gen-keyLa llave que crearemos tendrá las siguientes características:El tipo de claves será RSA, la opción por defecto.Tendrán un tamaño de 2048 bits. Las YubiKey no soportan un tamaño mayor.Podemos poner la caducidad que queramos, para este ejemplo la pondré de 6 meses.Se separarán las funciones de encriptar y autenticar en otras subclaves. Se hará más adelanteVoy a hacer una simulación creando la llave maestra, para que podáis ver el proceso completo.gpg (GnuPG) 2.2.32; Copyright (C) 2021 Free Software Foundation, Inc.This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Por favor seleccione tipo de clave deseado: (1) RSA y RSA (por defecto) (2) DSA y ElGamal (3) DSA (sólo firmar) (4) RSA (sólo firmar) (14) Existing key from cardSu elección: 1las claves RSA pueden tener entre 1024 y 4096 bits de longitud.¿De qué tamaño quiere la clave? (3072) 2048El tamaño requerido es de 2048 bitsPor favor, especifique el período de validez de la clave. 0 = la clave nunca caduca &lt;n&gt; = la clave caduca en n días &lt;n&gt;w = la clave caduca en n semanas &lt;n&gt;m = la clave caduca en n meses &lt;n&gt;y = la clave caduca en n años¿Validez de la clave (0)? 6mLa clave nunca caduca¿Es correcto? (s/n) sGnuPG debe construir un ID de usuario para identificar su clave.Nombre y apellidos: Ockham OdysseyDirección de correo electrónico: admin@odiseageek.esComentario: Ha seleccionado este ID de usuario: \"Ockham Odyssey &lt;admin@odiseageek.es&gt;\"¿Cambia (N)ombre, (C)omentario, (D)irección o (V)ale/(S)alir? vEs necesario generar muchos bytes aleatorios. Es una buena idea realizaralguna otra tarea (trabajar en otra ventana/consola, mover el ratón, usarla red y los discos) durante la generación de números primos. Esto da algenerador de números aleatorios mayor oportunidad de recoger suficienteentropía.Es necesario generar muchos bytes aleatorios. Es una buena idea realizaralguna otra tarea (trabajar en otra ventana/consola, mover el ratón, usarla red y los discos) durante la generación de números primos. Esto da algenerador de números aleatorios mayor oportunidad de recoger suficienteentropía.gpg: clave 61D4104EAD00CCE7 marcada como de confianza absolutagpg: certificado de revocación guardado como '/home/ockham/.gnupg/openpgp-revocs.d/B12F58499135721C09A1EEA261D4104EAD00CCE7.rev'claves pública y secreta creadas y firmadas.pub rsa2048 2022-03-10 [SC] [caduca: 2022-09-04] B12F58499135721C09A1EEA261D4104EAD00CCE7uid Ockham Odyssey &lt;admin@odiseageek.es&gt;sub rsa2048 2022-03-10 [E] [caduca: 2022-09-04]Ahora podemos ver las claves privadas que tenemos usando el siguiente comando:gpg -KEl resultado debería ser parecido al siguiente:gpg: comprobando base de datos de confianzagpg: marginals needed: 3 completes needed: 1 trust model: pgpgpg: nivel: 0 validez: 2 firmada: 0 confianza: 0-, 0q, 0n, 0m, 0f, 2ugpg: siguiente comprobación de base de datos de confianza el: 2022-09-04/home/ockham/.gnupg/pubring.kbx-------------------------------sec rsa2048 2022-03-10 [SC] [caduca: 2022-09-04] B12F58499135721C09A1EEA261D4104EAD00CCE7uid [ absoluta ] Ockham Odyssey &lt;admin@odiseageek.es&gt;ssb rsa2048 2022-03-10 [E] [caduca: 2022-09-04]Qué acabamos de hacerAhora bien, ¿qué significa todo lo que pone y qué se supone que acabamos de hacer? Hemos creado la llave maestra, de la que colgarán las otras claves. Si nos intentamos imaginar un llavero, podemos pensar que tenemos solo la arandela y la llave del portal de un edificio. Podemos acceder pero no entrar en la casa ni bajar al garaje, por ejemplo. Veamos las líneas una por una:sec nos indica que es la clave privada (secreta), seguido del tipo y la longitud que le hemos indicado (rsa2048) y la fecha de creación. SC lo explicaré más adelante. Luego aparece la fecha de caducidad y un identificador de la clave privada, no es la clave en sí.uid significa es el identificador de la clave, el propietario. Empieza con el nivel de confianza que tenemos con ese usuario, si somos nosotros mismos los que hemos creado esa clave la confianza será absoluta.ssb es la subclave secreta. Todo lo que aparece es exactamente igual exceptuando la \"E\" entre corchetes.Pasamos al significado de las palabras en corchetes. Las claves GPG pueden limitarse para usarse solo para ciertas cosas las cuales pueden ser firmar (S), certificar (C), encriptar (E) y autenticar (A). La llave maestra nos sirve para firmar documentos o certificar, que significa firmar otras claves. La certificación es utilizada principalmente para firmar nuestra siguiente clave GPG cuando la primera está a punto de caducar, y así el resto de usuarios puede asegurar que realmente es nuestra.Como podemos ver, no tenemos ninguna llave para autenticar (en el ejemplo del llavero podríamos decir que es el tener la llave de nuestro apartamento). Ahora vamos a crearla.Creación de subclavesComo ya tenemos la clave de encriptado, solo necesitamos crear la de autentificación. Primero accedemos al prompt para editar la clave.gpg --expert --edit-keySi tenemos más de una clave, tendremos que añadir también el ID, normalmente pulsando dos veces el tabulador salen las opciones.Ahora tendremos que usar el comando addkey para añadir una nueva subclave. El proceso será parecido a la creación de la llave maestra, será RSA de 2048 bits, pero personalizaremos las propiedades para indicar que solo puede autenticar. También le daremos una fecha de caducidad (en este ejemplo he puesto sin caducidad).gpg (GnuPG) 2.2.32; Copyright (C) 2021 Free Software Foundation, Inc.This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Clave secreta disponible.sec rsa2048/61D4104EAD00CCE7 creado: 2022-03-10 caduca: nunca uso: SC confianza: absoluta validez: absolutassb rsa2048/DEC2EC761F6A9986 creado: 2022-03-10 caduca: nunca uso: E [ absoluta ] (1). Ockham Odyssey &lt;admin@odiseageek.es&gt;gpg&gt; addkeyPor favor seleccione tipo de clave deseado: (3) DSA (sólo firmar) (4) RSA (sólo firmar) (5) ElGamal (sólo cifrar) (6) RSA (sólo cifrar) (7) DSA (permite elegir capacidades) (8) RSA (permite elegir capacidades) (10) ECC (sólo firmar) (11) ECC (permite elegir capacidades) (12) ECC (sólo cifrar) (13) Clave existente (14) Existing key from cardSu elección: 8Posibles accriones para una RSA clave: Firma Cifrado Autentificación Acciones permitidas actualmente: Firma Cifrado (F) Conmutar la capacidad de firmar (C) Conmutar la capacidad de cifrado (A) Conmutar la capacidad de autenticación (S) AcabadoSu elección:Lo siguiente es importante entenderlo bien. Conmutar significa cambiar de Sí a No o viceversa. Podemos ver arriba que las acciones actuales son Firma y Cifrado. Si seleccionamos la opción A se activará la opción de autenticar.Posibles accriones para una RSA clave: Firma Certificar Cifrado Autentificación Acciones permitidas actualmente: Firma Certificar Autentificación (F) Conmutar la capacidad de firmar (C) Conmutar la capacidad de cifrado (A) Conmutar la capacidad de autenticación (S) AcabadoSu elección:Ahora si seleccionamos la F, como ya estaba activada por defecto, se desactivará.Posibles accriones para una RSA clave: Firma Certificar Cifrado Autentificación Acciones permitidas actualmente: Certificar Autentificación (F) Conmutar la capacidad de firmar (C) Conmutar la capacidad de cifrado (A) Conmutar la capacidad de autenticación (S) AcabadoSu elección:Y hacemos lo mismo con la certificación, luego pulsamos S para continuar creando la clave.las claves RSA pueden tener entre 1024 y 4096 bits de longitud.¿De qué tamaño quiere la clave? (3072) 2048El tamaño requerido es de 2048 bitsPor favor, especifique el período de validez de la clave. 0 = la clave nunca caduca &lt;n&gt; = la clave caduca en n días &lt;n&gt;w = la clave caduca en n semanas &lt;n&gt;m = la clave caduca en n meses &lt;n&gt;y = la clave caduca en n años¿Validez de la clave (0)? 0La clave nunca caduca¿Es correcto? (s/n) s¿Crear de verdad? (s/N) sEs necesario generar muchos bytes aleatorios. Es una buena idea realizaralguna otra tarea (trabajar en otra ventana/consola, mover el ratón, usarla red y los discos) durante la generación de números primos. Esto da algenerador de números aleatorios mayor oportunidad de recoger suficienteentropía.sec rsa2048/61D4104EAD00CCE7 creado: 2022-03-10 caduca: nunca uso: SC confianza: absoluta validez: absolutassb rsa2048/DEC2EC761F6A9986 creado: 2022-03-10 caduca: nunca uso: E ssb rsa2048/6654BAD4D79CA815 creado: 2022-03-10 caduca: nunca uso: SEA [ absoluta ] (1). Ockham Odyssey &lt;admin@odiseageek.es&gt;Copia de seguridad de las claves secretasAhora que “el llavero” está completo podemos pasarlo a la YubiKey. Este proceso eliminará la clave privada de nuestro ordenador y la mantendrá solo en la YubiKey por lo que, si se extravía, ya no tendremos acceso a nuestra clave GPG. Para evitarlo, lo mejor será hacer una copia de seguridad y guardarla en otro lugar.gpg --export-secret-key --armor clave_secreta.asc&lt;/div&gt;gpg --export-secret-subkeys --armor subclaves_secretas.ascGenerar certificado de revocaciónSi por alguna razón se nos ha extraviado la clave privada o nos la han robado debemos revocarla, indicarle a todo el mundo que ya no es nuestra clave e invalidarla. Esto se consigue con un simple comando:gpg --output revoke.asc --gen-revokeMover las claves secretas a la YubiKeyEste es un proceso delicado si no hemos hecho el paso anterior, por eso vuelvo a insistir y recomiendo hacer una copia de seguridad de las claves antes. En esta fase se eliminarán las claves privadas y se almacenarán en distintas celdas de la tarjeta. Cada celda tiene un propósito; firmar, encriptar y autenticar; por eso hemos creado las subclaves. De esta forma la llave sabrá qué clave usar en qué momento. Por su parte, el sistema generará una referencia de nuestro llavero, indicando que las claves se almacenan en un dispositivo físico (smart card) y que debe ser insertada para utilizarse. La clave nunca se almacenará en el ordenador.gpg --edit-keyVeremos un menú parecido al siguiente:gpg (GnuPG) 2.2.32; Copyright (C) 2021 Free Software Foundation, Inc.This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Clave secreta disponible.sec rsa2048/61D4104EAD00CCE7 creado: 2022-03-10 caduca: nunca uso: SC confianza: absoluta validez: absolutassb rsa2048/DEC2EC761F6A9986 creado: 2022-03-10 caduca: nunca uso: E ssb rsa2048/6654BAD4D79CA815 creado: 2022-03-10 caduca: nunca uso: A [ absoluta ] (1). Ockham Odyssey &lt;admin@odiseageek.es&gt;Por defecto está seleccionada la clave maestra, como ya vimos antes, es la que pone sec.Aviso que como ya tengo mis claves en la tarjeta no he reproducido de nuevo los siguientes pasos, así que voy a sacar los ejemplos de la documentación.Escribimos en el prompt keytocard para enviarla a la tarjeta y seguimos los pasos que nos indica. La clave maestra es importante moverla a la celda de firma (signature) porque ya tenemos otra clave específica para la autentificación.gpg&gt; keytocardReally move the primary key? (y/N) ySignature key ....: [none]Encryption key....: [none]Authentication key: [none]Please select where to store the key: (1) Signature key (3) Authentication keyYour selection? 1gpg&gt; key 1sec 2048R/13AFCE85 created: 2014-03-07 expires: 2014-06-15 card-no: 0000 00000001ssb* 2048R/D7421CDF created: 2014-03-07 expires: neverssb 2048R/B4000C55 created: 2014-03-07 expires: never(1) Foo Bar &lt;foo@example.com&gt;Como también podemos ver en la captura de arriba, ahora aparece una línea que indica el número de nuestra YubiKey. Ahora, para guardar las subclaves usamos el comando key seguido del número de subclave por orden, siendo la primera ssb la key 1. La clave seleccionada aparecerá marcada con un asterisco.Con esto ya podemos añadir el resto de claves a sus respectivas secciones, no os lo voy a dar todo mascado.Con el comando quit salimos y, obviamente, guardamos los cambios.gpg&gt; quit¿Grabar cambios? (s/N) sOpcional: Requerir tocar la llave para usar las clavesUna de las cualidades de la YubiKey es que tiene una zona táctil, requiere pulsar está para comenzar con el proceso. Esto añade una capa de seguridad física, al hacer necesaria la interacción del usuario, es imposible que un hacker acceda a nuestra clave privada aunque la llave esté conectada y tenga acceso completo a nuestro ordenador.Para hacer esto primero necesitamos asegurarnos que tenemos el sistema de personalización de YubiKey que hemos instalado al principio. Ahora, con un comando, podemos habilitar la opción para la firma, la autentificación o la encriptación.Firmaykman openpgp keys set-touch SIG onEncriptadoykman openpgp keys set-touch ENC onAutenticaciónykman openpgp keys set-touch AUT onComprobaciónAhora podemos comprobar que las claves han cambiado de lugar con un simple comando que ya hemos visto.gpg -KLa salida será parecida a la siguiente./home/ockham/.gnupg/pubring.kbx-------------------------------sec&gt; rsa2048 2022-03-10 [SC] [caduca: 2022-09-04] B12F58499135721C09A1EEA261D4104EAD00CCE7uid [ absoluta ] Ockham Odyssey &lt;admin@odiseageek.es&gt;ssb&gt; rsa2048 2022-03-10 [E] [caduca: 2022-09-04]ssb&gt; rsa2048 2022-03-10 [A] [caduca: 2022-09-04]La diferencia es que en las claves ahora aparece el símbolo de mayor qué, esto significa que la clave no se encuentra en el ordenador, sino en la smart card. Ahora vamos a probar a firmar algo, un texto muy básico.echo \"test\" | gpg --clearsignSi la tarjeta no está conectada aparecerá lo siguiente:-----BEGIN PGP SIGNED MESSAGE-----Hash: SHA256testgpg: firma fallida: La tarjeta no estágpg: [stdin]: clear-sign failed: La tarjeta no estáSi la tarjeta está introducida se nos solicitará el código pin de la tarjeta, no es el de administrador, y aparecerá la firma. Recordad que si habéis seguido los pasos del punto anterior tendréis que tocar la tarjeta para que se efectúe la firma.-----BEGIN PGP SIGNED MESSAGE-----Hash: SHA256test-----BEGIN PGP SIGNATURE----- iQEzBAEBCAAdFiEE1lrNvaqfsNqeAgPEEA7DlDqoGQ0FAmIrNKMACgkQEA7DlDqoGQ3WFggAnCUW4mq1Vfn9IcNQMkAuWI3o8JJ/xpG7a7K6GbXl/vhrk57qzegwWGc5t3jTmcNqABqdJgqabG0rmiMKWfVMsjMAqXsjTsSjiuVmXuyGcLH0jUEjJLMiZuJthtIvgKdr1gUb9umITatqtZa2IzsChB8H3fYXYRoOU/hisWZ1zV+L3AkBpTXLsP23aDU0TLxaEWrOBytfVR5Q84d6zVbi5Bqoo0MEsyg7r/oXUDLXF+9rgBpCTmIFv3/oJYl2ZdFdrrrXlaGJUgkbBSmHwgNiZOFibRu5BR66FVD86HnOHoAl05mvK/BGjrnsKEGh24zUUdGrKqABoyEwEsDDN1CGCw===g6jR-----END PGP SIGNATURE-----Esta guía se ha hecho basándose en la experiencia propia, la documentación de Yubico y la guía de drduh en Github." }, { "title": "Mi experiencia en el mundo gaming con Linux. Por qué el futuro se ve prometedor", "url": "/posts/mi-experiencia-en-el-mundo-gaming-con-linux-por-que-el-futuro-se-ve-prometedor/", "categories": "Misceláneo", "tags": "Arch Linux, gaming, juegos, KDE, linux, Manjaro, Proton, ProtonDB, Steam, Valve", "date": "2022-03-05 16:31:29 +0100", "snippet": "Es innegable que Windows tiene una aplastante cuota de mercado en el mundo gaming, siendo prácticamente inexistente en Linux o Mac. Pero también hay que destacar que en los últimos años el gaming e...", "content": "Es innegable que Windows tiene una aplastante cuota de mercado en el mundo gaming, siendo prácticamente inexistente en Linux o Mac. Pero también hay que destacar que en los últimos años el gaming en Linux ha hecho el mayor avance desde sus inicios, y es que Valve, la empresa detrás de Steam, es gran responsable de esto. Para aquellos que no estén muy metidos en el tema vamos a ponernos en situación.Wine, Valve, Proton y SteamDeckWine es un programa de bajo nivel que permite la compatibilidad de aplicaciones de Windows en los sistemas Linux de una forma bastante peculiar, y es que no es un emulador, sino una capa intermedia entre la aplicación y Linux (es más, su nombre es el acrónimo recursivo de Wine Is Not Emulator). Su creación empezó a finales de los 90 y a día de hoy sigue actualizándose periódicamente detrás de una gran comunidad.El problema de Wine es que es complejo, y cada aplicación requiere unos parámetros y unas dependencias concretas. Aun así, muchos siguen dando problemas para ejecutarse por el Framework .NET de Microsoft. Y ahí es donde entra Valve, y es que la empresa detrás de la mayor plataforma de videojuegos para PC está luchando contra viento y marea para sacar adelante su proyecto Proton. Este es una versión de Wine adaptada para videojuegos y, aunque su software no tiene una licencia permisiva, mantiene el código abierto en un repositorio público de GitHub.Otro gran esfuerzo por parte de Valve ha sido la creación de su consola, la llamada Steam Deck, muy familiar a la Nintendo Switch. La Steam Deck es básicamente un ordenador de bolsillo capaz de correr una gran cantidad de juegos de Steam aunque con muy poca autonomía. Su sistema operativo, el SteamOS, está basado en ArchLinux, lo que ha hecho que los sistemas antitrampas y los desarrolladores de videojuegos tengan una presión extra a la hora de mantener la compatibilidad con Linux.Stardew Valley en Steam DeckLos sistemas antitrampasUn pequeño gran dolor de cabeza en el mundo Linux son los sistemas antitrampas de los juegos, y es que EasyAntiCheat y BattleEye están empezando a implementar ahora compatibilidad con Linux no sin problemas, y es que al parecer los antichetos siguen saltando dependiendo del kernel que se tenga instalado. Igualmente, ahora corresponde a los desarrolladores aplicar los cambios necesarios para esta compatibilidad, aunque el juego en sí no tenga soporte en Linux, Proton hará el resto.Mi experiencia jugandoHace poco más de dos años publiqué una entrada haciendo una pequeña comparativa con los juegos con los que más perdía el tiempo en esa época (antes del covid, no me lo creo), viendo su rendimiento en Windows, Linux con drivers de NVIDIA libres y los drivers propietarios. He de decir que me alegra que muchos de esos juegos ya funcionan genial.Aunque el tiempo haya pasado sigo usando mi querido Manjaro KDE y, aunque la gráfica sigue siendo la misma RTX 2060 SUPER, el procesador lo he cambiado de un i5-8500 a un Ryzen 5 3600.Algunos juegos que he probado aparecen como que tienen soporte nativo para Linux, como el Civilization VI, directamente ni arrancan. Los Metro 2033 y Metro Last Light también tiene soporte nativo, pero la calidad gráfica es peor y los FPS no suben de 30. A demás se me abren en la pantalla secundaria. La versión de Windows con Proton tira que no veas, todo al máximo y fluido. Juegos como el Rising Storm no lo he vuelto a probar en Linux, pero por lo que he visto su EAC aún nos echa de partida. El mítico Stardew Valley es el único que me va genial nativo, y ni lo he probado con Proton, la verdad es que es de los mejores juegos que he probado y me sigue flipando que lo haya hecho una sola persona.Si Portals y Halo hubieran tenido un hijo habría sido Splitgate, un juego frenético de disparos y portales. Es nativo aunque lo noto con pequeños tirones, seguro que con Proton va de lujo.Ahora mismo mi lista de juegos descargados en Linux es muy corta, dadme tiempo, pero estoy vigilando algunos en la web de Protondb para ver su compatibilidad.Fallout 4: Categoría Oro y verificado para Steam Deck.Rising Storm 2 Vietnam: Injugable por el antichetos.Firewatch: NativoStar Wars Jedi Fallen Order: Categoría Oro y verificado para Steam DeckBioshock Infinite: NativoDead by Deadlight: Injugable por el antichetos.Fallout 76: Categoría OroGTA IV: Categoría OroThe División: Categoría PlataQueda la Epic StorePrimero de todo hay que decir que la Epic Store no está disponible para Linux, pero eso no significa que no podamos jugarlos. Los fans han creado un lanzador de juegos llamado Heroic Games Launcher. Con este, podemos acceder a los juegos de nuestra biblioteca de Epic y descargarlos junto a una versión de Wine o Proton compatible. ¿A que es genial? Por mi parte tengo ahí el Subnáutica, el Red Dead Redemption y el Knockout City (todos con categoría oro) y la mar de contento.Emuladores por doquierNunca he sido muy fan de Nintendo, especialmente teniendo en cuenta sus reciclajes y su pésimo trato a los fans. Pero he de reconocer que tiene buenos juegos. Los Animal Crossing siempre los quise probar de pequeño y, aunque solo jugué a uno, los Pokemon también me han llamado la atención. Para ello, usando los emuladores de software libre Desmume y Citra, he podido probar estos juegos obtenidos de manera totalmente legal. A demás su soporte en Linux me parece tremendo. Cabe decir que Citra ahora también está disponible en la Play Store de Android." }, { "title": "Cómo conectarse por SSH sin contraseña de forma segura", "url": "/posts/como-conectarse-por-ssh-sin-contrasena-de-forma-segura/", "categories": "Sin categoría", "tags": "", "date": "2021-12-22 10:38:41 +0100", "snippet": "Durante la gestión de un servidor es importante mantener cierta seguridad y la mejor forma de evitar que descubran la contraseña de acceso es no tener contraseña. El servicio SSH permite identifica...", "content": "Durante la gestión de un servidor es importante mantener cierta seguridad y la mejor forma de evitar que descubran la contraseña de acceso es no tener contraseña. El servicio SSH permite identificar al cliente usando un par de claves criptográficas.Primero debemos crear desde el cliente las claves que usaremos, ssh nos ofrece una herramienta justo para eso.ssh-keygen -t rsa -b 2048 -f nombreSe nos creará la clave privada nombre y la clave pública nombre.pub de encriptación RSA y tamaño 2048 (no es recomendable usar un tamaño menor).La clave privada nos identificará en el servidor y la clave pública le indicará al servidor que realmente somos nosotros. Para añadir a nuestra identificación SSH la clave privada ejecutamos el siguiente comando:ssh-add nombreY ahora toca añadir a los servidores que queramos la clave.ssh-copy-id -i nombre usuario@serverNos pedirá la contraseña de acceso al servidor y se copiará.Ahora bien, podemos eliminar la posibilidad de iniciar sesión con contraseña, de forma que solo los usuarios@equipos que hayan seguido este procedimiento y el servidor tenga su clave pública podrán conectarse. Para hacer esto debemos editar el fichero de configuración del servicio ssh.sudo nano /etc/ssh/sshd_configY debemos añadir la siguiente líneaPasswordAuthentication noRecargamos el servidor y ya estará todo listosudo systemctl reload sshd" }, { "title": "Instalar ArchLinux con BTRFS y encriptación LUKS", "url": "/posts/instalar-archlinux-con-btrfs-y-encriptacion-luks/", "categories": "Apuntes ASIR, Implantación de Sistemas Operativos, Misceláneo", "tags": "Arch Linux, btrfs, encriptación, grub, linux, luks", "date": "2021-07-08 20:49:18 +0200", "snippet": "Tras varios meses usando Manjaro como sistema principal, viendo la comodidad que me aporta y los pocos problemas que he tenido (comparado con los que me dio Ubuntu), he decidido dar el paso de migr...", "content": "Tras varios meses usando Manjaro como sistema principal, viendo la comodidad que me aporta y los pocos problemas que he tenido (comparado con los que me dio Ubuntu), he decidido dar el paso de migrar a Arch Linux. Pero he decidido hacerlo a lo grande, y me veo ya capaz de instalar Arch Linux con el sistema BTRFS y encriptación LUKS en dos particiones distintas. No es moco de pavo, lo sé, por eso antes de aventurarme a lo loco he decidido documentarme, hacer una planificación y probar en un equipo externo. Tras lograrlo, he documentado los pasos por secciones. Es probable que no todo se deba realizar al pie de la letra para funcionar en otros equipos, es cuestión de entender las cosas y adaptarlas a las necesidades de cada uno. Dicho esto, empezamos.Descarga e instalación del archivo ISOComo siempre, debemos acceder a la página oficial de Arch Linux para descargar el archivo ISO actualizado. A diferencia de los sistemas operativos por versiones, las ISO desactualizadas no funcionarán. Para ello, habrá que acudir a la sección de descargas y navegar hasta el apartado HTTP Direct Downloads, donde buscaremos nuestro país o uno cercano y descargaremos la ISO desde allí. Si se vive en España recomiendo descargarlo desde el repositorio rediris o cloroformo, pero tengo constancia que en México pueden haber errores y es mejor descargar la versión de Estados Unidos.Ahora hay que quemar la imagen ISO en un USB vacío que tengamos. Para ello podemos usar el programa Rufus si trabajamos desde Windows o BalenaEtcher si estamos en GNU/Linux. Hay un poco más de información en la siguiente entrada.Ajustar el idioma del tecladoAntes de ponernos a tocar nada, debemos consultar unos datos y realizar algunas planificaciones, para ello tendremos que escribir algunos comandos. Por defecto, el teclado de Arch Linux está en inglés, así que cambiaremos el idioma a español para facilitarnos las cosas.loadkeys esPlanificar las particionesLo primero que tenemos que hacer es saber cuantos discos tenemos, cómo se llaman y si estamos usando una BIOS en modo UEFI o Legacy.lsblkY, para este ejercicio, supondremos que tenemos un disco sda con 120GB y un sdb de 1TB. El primero, sabiendo que es un SSD, lo usaremos para instalar el sistema operativo, el segundo será la partición /home. Ambas encriptadas.Ahora aparece un problema, si el directorio raíz está encriptado es posible que tengamos problemas a la hora de iniciar el sistema, así que tendremos que separar el o los directorios de arranque para que no se encripten.Para saber qué directorios de arranque tendremos que tener, hay que saber si nuestro ordenador funciona con BIOS o UEFI.ls /sys/firmware/efi/efivarsSi este comando nos da error, significa que estamos en BIOS/Legacy, si no devuelve error estamos en UEFI.Si estamos en BIOS, todas nuestras particiones deben ser MBR, también llamado DOS. Este tipo de particionado solo permite un total de 4 particiones, que se pueden dividir entre primarias y lógicas. Pero todo eso se especificará en otra entrada.Si estamos en UEFI, las particiones pueden ser tanto MBR como GPT, aunque es más recomendable la segunda, ya que da menos problemas y permite particiones casi ilimitadas, sin diferenciar entre primarias y secundarias.En nuestro caso estamos en modo UEFI, por lo que a partir de ahora nos centraremos en hacer las particiones para este sistema, todo lo demás puede hacerse igual. Esta es la planificación de nuestro particionado. Disco y partición Tamaño Tipo Formato sda1 260MiB EFI System FAT32 sda2 512MiB Linux filesystem EXT4 sda3 Todo Linux filesystem LUKS sdb1 Todo Linux filesystem LUKS Particionado de discosUsaremos la herramienta fdisk para modificar el primer discofdisk /dev/sdaSeleccionaremos la opción g para usar una tabla de partición GPT, luego con la n crearemos la primera partición.La primera opción es el número de la partición, nos aparece el 1 como opción por defecto así que damos a Enter. Luego nos indica cual será el primer sector y le damos a Enter para seleccionar también la opción por defecto. Después, nos pregunta cuanto medirá la partición, aquí tenemos que poner siempre un + seguido del número y M o G. En este caso seleccionamos 260MiB.Ahora, con la opción t editaremos el tipo de partición, si tenemos más de una nos preguntará cual queremos editar. Si no sabemos el código del tipo de partición que queremos podemos pulsar L para ver la lista de posibilidades. En nuestro caso queremos una partición EFI, cuyo código es el 1. Para las otras tres particiones el tipo de particionado no hace falta modificarlos.Realizamos los mismos pasos para la partición 2 y 3 del disco sda y la única partición de sdb.Formateo de particionesUna vez tenemos las cuatro particiones es hora de darles el formato que queramos. Para ellos tenemos la herramienta mkfs, abreviación en inglés de “Dar sistema de formato”. Como podemos ver en la tabla de arriba la primera y segunda partición son FAT32 y EXT4 respectivamente, simple. Las otras dos particiones aparece como formato LUKS, esto en realidad no es un formato de por sí, sino el método de encriptación, y se hace con el comando cryptsetup.Primero vamos a dar un formato FAT32 a la partición EFI, para eso ejecutamos este comando.mkfs.fat -F32 /dev/sda1Ahora daremos formato EXT4 a la partición boot. Con la opción -L añadimos lo que se llama labbel, que viene siendo una etiqueta, no es más que algo orientativo.mkfs.ext4 -L boot /dev/sda2Ahora solo nos quedan las dos particiones encriptadas. Para esto, primero debemos cargar en el kernel los módulos de encriptación. Son solo dos comandos.modprobe dm-cryptmodprobe dm-modTras esto, ciframos con LUKS las particiones sda3 y sdb1. Para confirmar, nos pedirá escribir YES en mayúsculas y luego la contraseña con la que vamos a encriptar los discos.cryptsetup luksFormat -v -s 512 -h sha512 /dev/sda3cryptsetup luksFormat -v -s 512 -h sha512 /dev/sdb1Desbloquear particiones encriptadasDebemos tener en cuenta que para poder utilizar las particiones encriptadas debemos desbloquearlas primero, eso hará que tengamos por un lado las particiones encriptadas “sdX”, y las particiones desencriptadas en mapper. Un ejemplo hará que lo entendamos mejor.Una partición encriptada se almacena en /dev/sda3, cuando la desencriptemos esta seguirá existiendo pero el acceso desencriptado se encontrará en /dev/mapper/foo, siendo foo una palabra clave que nosotros elegiremos. Para no complicarnos la vida haremos que la palabra clave de la partición sda3 sea “root” y la de sdb1 sea “home”.cryptsetup open /dev/sda3 rootcryptsetup open /dev/sdb1 homeTras poner un comando nos solicitará la contraseña de desencriptado que anteriormente le hemos puesto.Ahora podremos por fin formatear las particiones ahora desencriptadas, volveremos a usar la herramienta mkfs pero en las particiones mapper.mkfs.btrfs -L root /dev/mapper/rootmkfs.btrfs -L home /dev/mapper/homeSubvolúmenes BTRFSA parte de el soporte nativo de comprimirse a si mismo o la posibilidad de montarse mediante un RAID, el sistema de ficheros BTRFS también permite crear subvolúmenes. Un subvolumen es un árbol de archivos independiente en un sistema de ficheros que se monta dentro de directorio y puede poseer propiedades independientes. Para no petarnos la cabeza diremos que es una partición dentro de otra partición, no es realmente eso pero aquí nos servirá.Los subvolúmenes facilitan bastante la administración de los discos, por lo que vamos a utilizarlos en nuestro nuevo sistema. Para ello crearemos dos subvolúmenes dentro del mapper root, uno para el propio directorio raiz y otro como partición de las copias de seguridad del sistema. El mapper home tendrá también un subvolumen propio.Para ello primero debemos montar de forma temporal el mapper root, indicando que es una partición btrfs, y acceder al propio directorio.mount -t btrfs /dev/mapper/root /mnt; cd /mntAhora podemos crear los dos subvolúmenes.btrfs subvolume create rootbtrfs subvolume create snapshotsSalimos del directorio, desmontamos la partición, montamos la home y creamos su subvolumencd /umount /mntmount -t btrfs /dev/mapper/home /mntcd /mntbtrfs subvolume create homecd /umount /mntMontaje de las particionesAhora que hemos preparado todas las particiones y los subvolúmenes toca montarlos poco a poco. Hay que tener en cuenta que algunos puntos de montaje están dentro de otros, por lo que habrá que crear primero los directorios de montaje. Este es el orden que hay que seguir para montar las unidades.Primero montamos el subvolumen root en el que será el directorio raiz, ahora /mnt.mount -t btrfs -o subvol=root /dev/mapper/root /mntCreamos los directorios para el arranque del sistema.mkdir /mnt/bootmkdir /mnt/efiMontamos los directorios teniendo en cuenta la tabla del principio.mount /dev/sda2 /mnt/bootmount /dev/sda1 /mnt/efiCreamos y montamos el resto de particiones.mkdir /mnt/snapshotsmkdir /mnt/homemount -t btrfs -o subvol=snapshots /dev/mapper/root /mnt/snapshotsInstalación de paquetes básicosYa tenemos todos los discos particionados, formateados y en su sitio, es hora del plato principal: instalar Arch junto con los paquetes base para su funcionamiento. El procedimiento es más simple de lo que parece, se hace con un solo comando pero puede tardar algo de tiempo dependiendo del ordenador que tengamos.En este punto es importante añadir todos los paquetes que queramos instalar, esto incluye controladores, editores, gestores de red, Wi-Fi… Si uno se olvida siempre puede instalarlo más adelante pero puede ser más complicado.pacstrap -i /mnt base base-devel linux linux-firmware efibootmgr grub nano btrfs-progsCon todo ya instalado, se habrá creado todo el árbol de directorios de un sistema GNU/Linux dentro de /mnt, pero el fstab estará sin modificar o vacío, por lo que tendremos que crearlo. Por suerte, contamos una herramienta para ayudarnos con ello, un comando que muestra toda la configuración de los puntos de montaje.genfstab -U /mnt &gt; /mnt/etc/fstabAún no tenemos nuestro sistema preparado para usar, pero sí está listo para saltar a él y empezar con las configuraciones iniciales.Configuraciones básicasEstos pasos no os los debéis saltar, son totalmente necesarios para que el sistema arranque siquiera. Primero “saltaremos” al nuevo sistema para poder realizar las instalaciones.arch-chroot /mntAhora somos el usuario root de nuestro nuevo sistema, pero funcionando bajo el soporte del instalador. Aun así, todos los cambios que realicemos ahora se implementarán en el nuevo sistema. No sé si es la mejor comparativa pero digamos que es como realizar reparaciones a un barco en dique seco.Añadir contraseñaLo primero que vamos a hacer es darle una contraseña al usuario root.passwdCambiar idioma del sistemaAhora pondremos el idioma en español. Para eso entramos en el fichero /etc/locale.gen y vamos bajando hasta encontrar la versión UTF-8 de tu idioma regional. Si eres de España probablemente te interese es_ES.UTF-8.Cuando encuentres tu idioma elimina la almohadilla de esa línea. Puedes hacerlo con todos los idiomas que quieras.Ahora aplicaremos los cambios.locale-genLo siguiente es configurar la hora local. Para ello haremos un enlace simbólico a la hora de nuestra región. Al ser de España, seleccionaré la hora de Madrid, pero puedes seleccionar cualquier otra región del mundo cambiando de ciudad y continente.Establecer horarioln -sf /usr/share/zoneinfo/Europe/Madrid /etc/localtimeActualizamos el reloj físico del ordenador a la nueva hora del sistema.hwclock --systohc --utcNombre del equipoEs muy importante darle un nombre al equipo, esto nos ayudará a identificarlo en la red. Para cambiar el nombre del equipo hay que modificar dos ficheros. El nombre puede ser el que sea (sin espacios ni caracteres especiales), yo llamaré a mi equipo “arch”, deberás realizar los mismos pasos sustituyendo “arch” por el nombre del equipo que tu quieras.echo arch &gt; /etc/hostnameEl siguiente archivo lo tendremos que modificar a mano, tendrá que quedar más o menos así”Modificar el arranqueVale, por el título puede dar miedo, pero solo tendremos que modificar un archivo, el que le indica al GRUB cómo debe comportarse.nano /etc/default/grubDentro de este archivo tendremos que cambiar el GRUB_CMDLINE_LINUX indicando que debe desencriptar la partición donde se encuentra el directorio raiz, seguido del nombre del mapper quedando de esta forma: GRUB_CMDLINE_LINUX=\"cryptdevice=/dev/sda3:root\".Ahora modificaremos también el script de configuración para la creación del initrd, básicamente para la creación del núcleo de arranque.nano /etc/mkinitcpio.confDentro de este fichero buscaremos el primer “HOOKS” que no esté comentado con una almohadilla y lo modificaremos haciendo que quede de la siguiente forma: HOOKS=(base udev autodetect keyboard keymap consolefont modconf block encrypt filesystem fsck).Una vez modificado, ejecutaremos el script para crear el núcleo de arranque Linux.mkinitcpio -PDesencriptar home al arranqueComo hemos podido observar en el punto anterior, solo hemos indicado que se debe desencriptar el directorio raíz. Para marcar que se debe desencriptar el disco sdb1 debemos modificar el archivo crypttabnano /etc/crypttabQuitaremos la almohadilla de la línea home, cambiaremos la sección “device” por nuestro disco (/dev/sda3) y eliminaremos la línea de password.Esto hará que nos solicite dos contraseñas al arranque, una para la raíz y otra para el home. Si no queremos que nos solicite la contraseña para el home tendremos que crear un archivo con la contraseña, cambiar los permisos para que solo pueda leerlo el root y añadir la ubicación en la sección “password”.Instalar gestor de redPor último pero no por ello menos importante debemos instalar algún sistema gestor de redes, esto sirve para poder detectar las redes WiFi o configurar las conexiones Ethernet. Es importante instalar únicamente un gestor de redes, porque podría causar conflicto. En este caso instalaremos NetworkManager, uno de los más extendidos.pacman -S networkmanagerAhora debemos indicarle al sistema que lo inicie cada vez que se arranca el sistema. Es importane escribir las mayúsculas donde toca para que funcione.systemctl enable NetworkManagerSi mal no recuerdo, al conectar un cable de red la conexión es automática, pero para conectarse a una red WiFi desde la línea de comandos seguimos estos pasos: primero escaneamos en busca de todas las redes disponibles.nmcli device wifi listDespués nos conectamos a la red que queramos de la siguiente forma.nmcli device wifi connect \"red_wifi\" password \"contraseña\"Sustituimos “red_wifi” por el nombre de la red y “contraseña” por la contraseña de la red, fácil y para toda la familia.Configurar GRUBAhora toca el último paso y uno de los más delicados. Dependiendo de cómo se haya instalado el sistema, la ubicación de las particiones y si el ordenador es UEFI o BIOS se tendrá que ejecutar de una forma u otra. Tal y como lo hemos hecho aquí, tenemos que hacer lo siguiente.grub-install --boot-directory=/boot --efi-directory=/efi /dev/sda2De esta forma, indicamos dónde está el directorio boot y el directorio efi para que el grub cree las carpetas que necesite dentro de estos. Si todo ha ido bien, dentro de /efi el sistema habrá creado otra carpeta EFI y dentro el nombre de nuestro sistema. Ahora toca plasmar la configuración del grub a ambos directorios de arranque.grub-mkconfig -o /boot/grub/grub.cfggrub-mkconfig -o /efi/EFI/arch/grub.cfgUna vez esto termine, podremos apagar el ordenador, quitar el USB de instalación y volver a encenderlo. Si todo ha ido correctamente tendrá que salir el GRUB con Arch Linux como opción de arranque y, una vez haya iniciado, solicitará la contraseña de las particiones encriptadas antes de arrancar definitivamente." }, { "title": "En qué se diferencia la URL, URI y URN", "url": "/posts/en-que-se-diferencia-la-url-uri-y-urn/", "categories": "Sin categoría", "tags": "redes, uri, url, urn", "date": "2021-06-18 11:54:34 +0200", "snippet": "Prácticamente todos hemos escuchado el término URL, link, enlace, hipervínculo… Básicamente todo eso viene a ser lo mismo, pero URL tiene un significado muy concreto, y viene de la mano de otros té...", "content": "Prácticamente todos hemos escuchado el término URL, link, enlace, hipervínculo… Básicamente todo eso viene a ser lo mismo, pero URL tiene un significado muy concreto, y viene de la mano de otros términos como URI o URN.En general solemos usar URL para todo, y seguramente hayas llegado hasta aquí porque has leído o escuchado URI o URN y no sabes lo que significa.Primero de todo debemos saber cómo funciona un enlace, para ello vamos a poner un ejemplo y nos vamos a basar en este durante todo el artículo.https://odiseageek.es/post/2187#commentsURLLa URL o Localizador de Uniforme de Recursos, indica la ubicación del recurso al que estamos accediendo y el protocolo que se está utilizando. Con esto podemos deducir que la URL debe ser única e incluye el dominio y la ubicación a la que accedemos, lo que viene siendo lo siguiente:https://odiseageek.es/post/2187URNPor otro lado, la URN o Nombre Uniforme de Recursos, nos indica la ubicación del recurso y el nombre del propio recurso pero no el protocolo que se utiliza para llegar a este. No te preocupes, al final de la entrada hay una imagen que lo dejará todo mucho más claro.Para que la gente entendida no se cabree voy a especificar que en realidad la URN tiene una estructura más técnica, estandarizada y estrechamente relacionada con el código XML que acompaña a toda página web, pero no vamos a entrar en eso ahora mismo. Lo importante es ver dónde se encuentra dentro de los hipervínculos.odiseageek.es/post/2187#commentsURIPor último y, probablemente, menos complicado está la URI o Identificador Uniforme de Recursos. La URI es simplemente la unión de la URL y la URN, indica la ubicación, el protocolo y el nombre del recurso al que accedemos. Ahora bien, veremos todo esto y qué es lo que se llama “recurso” con una simple imagen." }, { "title": "Cómo y porqué activar la licencia de Windows en máquinas virtuales", "url": "/posts/como-y-porque-activar-la-licencia-de-windows-en-maquinas-virtuales/", "categories": "Apuntes SMR, Sin categoría, Sistemas Operativos Monopuestos y en Red", "tags": "licencia, virtual box, windows", "date": "2021-05-09 20:47:22 +0200", "snippet": " Esta no es una solución oficial, puede no ser válida según la máquina virtual, modelo o versión del sistema operativo.Todos sabemos que para utilizar todas las funciones de los sistemas Windows s...", "content": " Esta no es una solución oficial, puede no ser válida según la máquina virtual, modelo o versión del sistema operativo.Todos sabemos que para utilizar todas las funciones de los sistemas Windows se necesita introducir una licencia. Las licencias son códigos que demuestran que has pagado por el producto y debes introducir en el sistema para tener todas las funcionalidades. Pagar por usar una máquina virtual tiene poco sentido, Microsoft lo sabe, por ese mismo motivo sus máquinas virtuales pueden activarse sin poseer una licencia.Por qué activar Windows en una máquina virtualMicrosoft permite el uso de Windows sin licencia por tiempo ilimitado, pero restringe ciertas funciones que pueden ser importantes. Cambiar le tema o el fondo de pantalla estará bloqueado si Windows no está activado. A parte que aparecerá una marca de agua en la parte inferior derecha. Si se trata de una máquina Windows Server las restricciones también son mayores, ya que la máquina se reiniciará de forma aleatoria, algo bastante grave en servidores.Aunque no está 100% probado, siempre he experimentado pérdidas de rendimiento en las máquinas que no se solucionaba hasta activar Windows.Cómo activar Windows gratis en máquinas virtualesEste proceso funciona en máquinas Windows 10, Windows 7 y las distintas versiones de Windows Server.Lo primero de todo es comprobar que Windows no está activado, en muchas ocasiones se activa solo al detectar que se encuentra en una máquina virtual. Para ello debes acceder al apartado de sistema de la máquina virtual y revisar el apartado de activación.Muestra de activación en Windows 7En caso de que no esté activado debemos abrir un terminal como administrador. Podemos comprobar que tenemos los privilegios porque aparecerá “system32” en en prompt.Tras esto escribimos el siguiente comando:slmgr /rearmNos aparecerá la siguiente ventana, la cual nos indica que se ha renovado la licencia de Windows en la máquina virtual.Tras esto, reiniciaremos la máquina virtual y deberíamos contar con una licencia válida.Un apunte más…Me gustaría aclarar que este proceso solo funciona en máquinas virtuales, para poder usar Windows en una máquina real se debe comprar una licencia legal. Desde este blog no fomentamos en ningún momento el uso de piratería ni daremos facilidades para su uso." }, { "title": "Restaurar versión anterior de GRUB en Manjaro", "url": "/posts/restaurar-version-anterior-de-grub-en-manjaro/", "categories": "Misceláneo", "tags": "GRUB, Linux, Manjaro", "date": "2021-03-18 13:50:49 +0100", "snippet": "Hace pocos días tomé la decisión de actualizar el portátil y me sorprendió que el grub estuviese en la lista de actualizaciones. Al poco tiempo, al volver a encender el ordenador, me di cuenta que ...", "content": "Hace pocos días tomé la decisión de actualizar el portátil y me sorprendió que el grub estuviese en la lista de actualizaciones. Al poco tiempo, al volver a encender el ordenador, me di cuenta que no aparecía Windows 10 en la lista de arranque. Tras un pequeño e improvisado intento de solucionarlo, el grub dejó de funcionar.El error que me aparecía era poco común: symbol_grub_disc_native_sectors not foundTras indagar un poco, otro de los errores que me aparecía era: error: symbol \"grub_register_command_lockdown\" not foundUn poco metida de pata, vamos. Al final logré encontrar una lista de mensajes enviados en el registro de bugs de Debian de hace apenas 10 días donde intentaban solucionar este error. En concreto, estos mensajes.Las soluciones aportadas eran para Debian, poco me servían. Pero al saber que el problema se trataba de la versión del GRUB decidí bajar a una versión anterior.Solución desde liveEra imposible acceder al sistema con el GRUB dañado, así que accedí desde un USB a una versión live de Manjaro. Desde ahí, el sistema ofrece herramientas para acceder al sistema instalado en el ordenador y ejecutar órdenes en este desde el live. Esto es clave para reinstalar el grub.Usando el comando manjaro-chroot -a accedemos al sistema host y todos los cambios que realicemos le afectarán directamente. Ahora tenemos que instalar la herramienta para bajar la versión de los programas.yay -S downgradeAhora podemos cambiar el grub a una versión anterior a la 21, que es la dañada. Una vez hecho esto, podemos reiniciar el equipo y ya podremos acceder de nuevo al sistema del ordenador.Mantener la versión antigua del GRUBUno de los problemas que tendremos ahora es que el sistema reconocerá que el GRUB está desactualizado e intentará volver a la última versión. Para evitar esto se debe editar la configuración de pacman, el gestor de paquetes de Arch Linux.sudo nano /etc/pacman.confAñadimos el grub al apartado de paquetes a ignorar para que no se actualice.Podemos ver como aparece indicado que se ignorará el paquete grub aunque esté desactualizado. Todo este proceso podemos seguirlo también para otras aplicaciones cuyas últimas versiones son den problemas y volver a actualizarlas cuando se resuelva el problema." }, { "title": "Montar unidades SMB o CIFS en Linux con mount o fstab", "url": "/posts/montar-unidades-smb-o-cifs-en-linux-con-mount-o-fstab/", "categories": "Sin categoría", "tags": "cifs, linux, samba", "date": "2021-02-16 10:46:27 +0100", "snippet": "Hace relativamente poco creé un pequeño servidor samba en mi casa con la idea de poder visualizar y publicar archivos en un único lugar conjunto (la idea de tener mi propia nube personal me abruma ...", "content": "Hace relativamente poco creé un pequeño servidor samba en mi casa con la idea de poder visualizar y publicar archivos en un único lugar conjunto (la idea de tener mi propia nube personal me abruma desde hace años, muchos lo saben). Pero el sistema que se usa generalmente en Linux y en Windows es distinto, Windows monta la unidad en un nuevo disco (el Z: por defecto) mientras que en Linux debes acceder como ubicación remota. Esto genera ciertos problemas, especialmente a la hora de acceder desde algunas aplicaciones que no aceptan archivos remotos.Por eso decidí indagar en el tema y, a decir verdad, pocas cosas me funcionaban. Hasta le pedí ayuda a una profesora mía. Todo eso, junto con las consultas incesantes a los manuales del sistema dieron sus frutos. Al fin y al cabo, no estaría escribiendo esto si no lo hubiese conseguido, ¿no es así?Montaje manual (mount)Primero de todo debía encontrar la forma de montar la unidad sin explotar, luego me encargaría de hacer que el sistema la monte automáticamente. Recopilando la información de varios blogs y foros, junto con los incontables fallos que tuve, encontré la solución a toda la parafernalia. Voy a indicar el comando interminable que debe usarse y a explicar el porqué de cada cosa.sudo mount -t cifs //server/data /local -o username=sambauser,password=paswd,iocharset=utf8,uid=localuser,gid=localgroup,forceuid,forcegid,cifsaclQué hace cada cosasudo: Indicamos que el comando debe ejecutarse como root. Obviamente para ello nuestro usuario tendrá que estar en la lista sudousers.mount: El comando a ejecutar. Mount es usado principalmente para montar y visualizar las particiones del sistema.-t cifs: Le indicamos al comando mount que debe utilizar el sistema de ficheros CIFS. Este es el nombre que usa Windows para el protocolo SMB. Según los manuales también se puede usar smbfs, pero este nunca me ha funcionado.//server/data: Debemos indicar la dirección IP del servidor al que nos queremos conectar usando primero dos barras ( // ). Si nos queremos conectar a un directorio específico lo indicaremos usando otra barra y la dirección./local: Indicamos en qué directorio local queremos que se monte, puede estar colgando del directorio raíz o de dónde sea, pero siempre indicar una ruta absoluta. Separaremos esta información de la del servidor con un espacio-o: Ahora viene lo tocho. Con -o avisamos a mount que vamos a especificar todos los requerimientos para el montaje. Debe colocarse todo sin espacios.username=sambauser: Cambiamos \"sambauser\" por el nombre de usuario de samba con el que nos vamos a conectar. No pasa nada si ese usuario no existe en el sistema.password=paswd: Cambiamos \"paswd\" por la contraseña del usuario samba. Como he dicho antes, no tiene por qué coincidir con alguna contraseña local. Tanto el usuario como la contraseña o el dominio (que no lo vamos a usar aquí), se pueden guardar en un archivo protegido (pero no cifrado que yo sepa) para evitar a los curiosos.iocharset=utf8: Con esto especificamos el tipo de codificación que tienen los archivos. Usando esto evitamos problemas de compatibilidad con otros ordenadores que estén conectados.uid=localuser: Cambiamos \"localuser\" por un usuario del sistema. Una de las guindas del pastel. Con este opción marcamos el usuario local que va a conectarse a samba. El sistema cogerá los permisos del usuario \"sambauser\" que hemos indicado arriba y sustituirá en el montaje los permisos de este dándoselos al usuario \"localuser\". gid=localgroup: Cambiamos \"localgroup\" por un grupo del sistema local. Al igual que la opción anterior, montará los ficheros y directorios poniendo a \"localgroup\" los permisos que en samba le corresponden al grupo de \"sambauser\". forceuid,forcegid: Añadimos estas opciones cuando el usuario y el grupo del sistema no coinciden con el usuario y el grupo con el que queremos acceder a samba. cifsacl: Debemos marcar esta opción para asegurarnos que los permisos se añaden correctamente durante el montaje. Con esto no solo evitamos problemas de no poder escribir en ciertos archivos, sino también de no acceder a las carpetas a las que realmente no tenemos permisos.Ejemplo prácticoEn teoría, con toda esta parafernalia, ya lo tenemos listo. Por si a alguien le ha petado una neurona voy a indicar un ejemplo práctico.:sudo mount -t cifs //192.168.0.20/data /home/crotofroto/Datos -o username=owo,password=fakepassword,iocharset=utf8,uid=crotofroto,gid=crotofroto,forceuid,forcegid,cifsaclUna vez nada de esto nos dé error significa que ya podemos montar la unidad samba en el sistema como si de un directorio más se tratase.Se eres inconformista no te querrás quedar aquí, porque tras cada inicio de sistema tendrás que ejecutar el comando para que funcione. Y sí, podrías crear un script y añadirlo al crontab para que se monte siempre que enciendas el ordenador, pero hay una opción mucho mejor.Montaje automático (fstab)El fichero /etc/fstab sirve para mostrar y editar los montajes del sistema. Dependiendo del nuestro, estará más o menos lleno. Lo importante es no tocar nada de lo que hay ya escrito, porque podríamos hacer que el ordenador no se vuelva a encender.Ahora que ya tienes el miedo en el cuerpo, asegúrate de empezar a editar desde abajo añadiendo la siguiente línea://server/data /local cifs username=sambauser,password=paswd,iocharset=utf8,uid=localuser,gid=localgroup,forceuid,forcegid,cifsacl,noauto,x-systemd.automount,_netdev 0 0Puedes deducir que tiene los mismos datos que el comando mount solo que con una estructura distinta. Es importante que lo coloques toda tu configuración en ese orden y con el mismo espaciado para evitar problemas.También podrás ver que al final tiene cinco parámetros nuevos.Qué hace cada cosanoauto,x-systemd.automount: Estas dos opciones suelen usarse cuando se tratan de particiones grandes. La primera indica que no se monte automáticamente al arrancar el sistema, esto se hace porque puede ralentizar significativamente el inicio. La segunda opción le dice al kernel que únicamente monte la partición cuando se va a acceder a ella por primera vez. De forma que para nosotros se sigue montando automáticamente pero sin ralentizar el sistema. La segunda opción depende directamente del demonio systemd que, por suerte o por desgracia, se encuentra en casi todos los sistemas Linux más utilizados._netdev: Por inventarme algo vamos a traducirlo como \"network device\". Esta opción indica que la partición depende directamente de la red, por lo que no debe montarse si no está la red preparada para comunicarse con otros dispositivos y así evitar errores.0 0: Tu pon los dos ceros que sino no va. El porqué se colocan no forma parte de la explicación de esta entrada.Más informaciónSi tienes más dudas o errores o quieres colocar más opciones de montaje, te facilito aquí la wiki de ArchLinux, la cual me ha ayudado enormemente a poder solucionar todos los errores que me he ido encontrando y cuenta con muy buenas explicaciones tanto en inglés como en español.Aunque uses un sistema Debian, todo lo aquí mencionado me ha servido tanto en Manjaro como en Ubuntu.&lt;/p&gt;Información sobre samba: https://wiki.archlinux.org/index.php/sambaInformación sobre fstab: https://wiki.archlinux.org/index.php/Fstab_(Espa%C3%B1ol)" }, { "title": "Signo y magnitud, complemento a 1 y a 2 y el exceso Z para tontos", "url": "/posts/signo-y-magnitud-complemento-a-1-y-a-2-y-el-exceso-z-para-tontos/", "categories": "Apuntes ASIR, Fundamentos del Hardware", "tags": "aritmética, binario, complemento, resta, suma", "date": "2020-12-18 00:11:00 +0100", "snippet": "La aritmética binaria, al igual que toda rama de las matemáticas, puede ser tediosa, frustrarte y complicada si no se tiene una explicación simple y unas buenas bases. En esta entrada intentaré exp...", "content": "La aritmética binaria, al igual que toda rama de las matemáticas, puede ser tediosa, frustrarte y complicada si no se tiene una explicación simple y unas buenas bases. En esta entrada intentaré explicar las operaciones de suma y resta utilizadas por las máquinas de la manera lo más simple que pueda.Para empezar, debemos comprender que las máquinas funcionan con el sistema binario (del 0 al 1), y no con el decimal (del 0 al 9). Para diferenciarlo y remarcarlo pondremos a veces los números en base 10 (n10) o en base 2 (n2).IntroducciónAntes que nada, debo remarcar que esto se puede realizar con cualquier cantidad de bits, pero en esta entrada solo usaremos 4 bits para mostrar ejemplos más sencillos.Los bits en binario irán del 0000 al 1111, el valor de estos tendrán un significado diferente en cada ocasión, tendremos tablas para mostrarlo más visualmente.Signo y MagnitudEl sistema de Signo y Magnitud utiliza el primer bit para identificar si el número es positivo o negativo, 0 indica que el número es positivo y 1 negativo. De esta forma, con un total de 4 bits, podemos obtener desde el 7 hasta el -7. El número 0 también tiene su contraparte negativa. Número decimal Representación Signo y Magnitud 8 - 7 0111 6 0110 5 0101 4 0100 3 0011 2 0010 1 0001 0 0000 -1 1001 -2 1010 -3 1011 -4 1100 -5 1101 -6 1110 -7 1111 -8 - Cuando sumar y cuando restarEs importante saber en qué momento hay que operar con suma y en cual se utiliza la resta. En el caso del Signo y Magnitud se realiza una suma cuando los signos son iguales, y se resta cuando son distintos signos.Tenemos que tener en cuenta que en -5 - 4 se tendría que realizar una suma, porque el signo - se lo lleva el 4, resultando en -5 + (-4) y ambos dígitos tienen el mismo signo.SumaLa suma en Signo y Magnitud se realiza como una suma binaria normal y corriente, obviando el primer dígito, que indica el Signo.En las sumas ambos signos son iguales, por lo que el signo se mantiene, ya sea 1 o 0.RestaLa resta se hace cuando el signo de ambos números es distinto. Se opera como una resta normal, apartando los símbolos. El símbolo que queda como resultado es el del número de mayor magnitud.     Complemento a 1La representación del complemento a 1 (a partir de ahora C1) utiliza como base el Signo y Magnitud. El C1 no varía frente al Signo y Magnitud cuando se trata de números positivos. En los números negativos se debe calcular la diferencia entre el número máximo (710 en nuestro caso porque nuestro máximo binario es 1112) y nuestro número. Por ejemplo, el C1 de 6 es 1 porque solo le falta 1 número para llegar a 7, el C1 de 3 es 4 porque le faltan 4 números para llegar a 7.Una forma rápida de calcular esto en binario es invirtiendo la magnitud de los números negativos. Siempre manteniendo intacto el primer bit, porque este indica el signo. Quedando así el 1100 como 1011. A continuación una tabla comparativa. Decimal Signo y Magnitud Complemento a 1 8 - - 7 0111 0111 6 0110 0110 5 0101 0101 4 0100 0100 3 0011 0011 2 0010 0010 1 0001 0001 0 0000 0000 -0 1000 1111 -1 1001 1110 -2 1010 1101 -3 1011 1100 -4 1100 1011 -5 1101 1010 -6 1110 1001 -7 1111 1000 -8 - - Cuando sumar y cuando restarLa norma de oro es que siempre se suma en los complementos. Cuando se trata de 5 + 2 puede parecer fácil, pero cuando nos encontramos un 5 - 2 debemos juntar el signo - con el número siguiente, quedando así 5 + (-2).Con los números negativos pasa lo mismo, un -5 - 2 se transforma en -5 + (-2).SumaEn este caso, a diferencia del Signo y Magnitud, el signo se incluye en la suma.Habrá ocasiones donde aparezca un exceso. El exceso es aquel número que sobrepasa el límite de nuestras operaciones. En este caso, trabajamos con un máximo de 4 dígitos (de 0000 a 1111), un exceso sería el 10000.Cuando aparece un exceso, se retira y se suma al resultado. Aquí vemos un ejemplo:Podemos comprobar en la tabla de arriba como 1001 coincide con -6 en C1.Complemento a 2Para conseguir el Complemento a 2 (a partir de ahora C2) se debe obtener primero el C1 y sumarle 1 a los número negativos. El objetivo de esto es evitar la suma del número excedido que se realiza siempre en el C1. Como siempre, aquí vamos con una tabla comparativa. Decimal Signo y Magnitud Complemento a 1 Complemento a 2 8 - - - 7 0111 0111 0111 6 0110 0110 0110 5 0101 0101 0101 4 0100 0100 0100 3 0011 0011 0011 2 0010 0010 0010 1 0001 0001 0001 0 0000 0000 000 -0 1000 1111 - -1 1001 1110 1111 -2 1010 1101 1110 -3 1011 1100 1101 -4 1100 1011 1100 -5 1101 1010 1011 -6 1110 1001 1010 -7 1111 1000 1001 -8 - - 1000 SumaCon el cambio que ya hemos realizado en la tabla, a partir de ahora la suma se realiza exactamente igual. La única diferencia ahora es que el número excedente se descarta en lugar de sumarlo. Recordamos que los positivos son iguales en el C2, el C1 y el Signo y MagnitudExceso ZEl Exceso Z varía dependiendo de la cantidad de dígitos con los que trabajemos, en este caso solo con 4. Para calcular el Exceso Z tenemos que saber que Z = 2(n-1) siendo n el número de dígitos. Z = 2(4-1) = 23 = 8. Con esto conseguimos saber cual es el número máximo que podemos obtener. Como podemos observar en las tablas de arriba, el número 8 y -8 siempre aparecen como primera y última opción.Ahora que conocemos el número mínimo y máximo, tenemos que tener en cuenta que el mínimo será el 0 a partir de ahora, en otras palabras, -810 = 00002. Para tenerlo de forma más visual y con sentido, vamos a ver la tabla. Decimal Signo y Magnitud Complemento a 1 Complemento a 2 Exceso Z 8 - - - - 7 0111 0111 0111 1111 6 0110 0110 0110 1110 5 0101 0101 0101 1101 4 0100 0100 0100 1100 3 0011 0011 0011 1011 2 0010 0010 0010 1010 1 0001 0001 0001 1001 0 0000 0000 000 1000 -0 1000 1111 - - -1 1001 1110 1111 0111 -2 1010 1101 1110 0110 -3 1011 1100 1101 0101 -4 1100 1011 1100 0100 -5 1101 1010 1011 0011 -6 1110 1001 1010 0010 -7 1111 1000 1001 0001 -8 - - 1000 0000 Si se es observador, se puede ver como el Exceso Z es igual al C2 con el signo invertido. Esta es una forma más fácil de obtenerlo.Cuando sumar y cuando restarYa hemos visto como en Signo y Magnitud se sumaba con los signos iguales y restaba con signos distintos, y en los complementos siempre se suma. En este caso, nuestro objetivo será hacer que ambos números tengan el mismo signo.Una vez hayamos preparado la operación, será hora de sumar o restar dependiendo de las circunstancias.SumaInicialmente, la suma se realiza de forma normal, teniendo en cuenta el signo durante la operación. Tras sumar, debemos restar el Exceso Z, recordamos que en nuestro caso es 810 = 10002. Siempre va a ser un 1 en la posición más alta, seguido de 0 en el resto de posiciones.RestaEn el caso de la resta, también haremos la operación de forma normal. Cuando tengamos el resultado, tendremos que sumar el Exceso Z.&lt;/p&gt;" }, { "title": "Mostrar asteriscos al escribir la contraseña de GNU/Linux", "url": "/posts/mostrar-asteriscos-al-escribir-la-contrasena-de-gnu-linux/", "categories": "Misceláneo", "tags": "asteriscos, contraseñas, gnu, linux, seguridad", "date": "2020-10-17 13:07:00 +0200", "snippet": "Estoy seguro que, a aquellos que vienen de Windows, el escribir una contraseña en el terminal y que no aparezca nada les resultó chocante, al menos la primera vez. Esto pude ser un problema para us...", "content": "Estoy seguro que, a aquellos que vienen de Windows, el escribir una contraseña en el terminal y que no aparezca nada les resultó chocante, al menos la primera vez. Esto pude ser un problema para usuarios novatos, gente con contraseñas largas o con problemas con el teclado, etc. Para solucionar esto, podemos permitir que aparezcan asteriscos cada vez que escribimos la contraseña en el terminal.Para ello tenemos que editar el archivo sudoers, este es muy importante por lo que haremos una copia de seguridad por si acaso.sudo cp /etc/sudoers /etc/sudoers.bakAhora podemos entrar a editar este fichero. No debe hacerse de la forma tradicional, usando el comando nano. Usaremos un comando específico para esta operación.sudo visudoBuscaremos la línea que aparece enmarcada y le añadiremos pwfeedback quedando de la siguiente forma:Al guardar y salir, podremos comprobar como aparecen los asteriscos al escribir la contraseña." }, { "title": "Arquitectura Von Neumann. Qué es y cómo funciona", "url": "/posts/arquitectura-von-neumann-que-es-y-como-funciona/", "categories": "Apuntes ASIR, Apuntes SMR, Fundamentos del Hardware, Implantación de Sistemas Operativos, Sistemas Operativos Monopuestos y en Red", "tags": "", "date": "2020-09-20 15:53:37 +0200", "snippet": " Puedes profundizar conceptos en la segunda parte; con más datos, detalles e imágenes. Arquitectura Von Neumann. Qué es y cómo funciona.Los primeros ordenadores, surgidos en la década de los 40 en...", "content": " Puedes profundizar conceptos en la segunda parte; con más datos, detalles e imágenes. Arquitectura Von Neumann. Qué es y cómo funciona.Los primeros ordenadores, surgidos en la década de los 40 en adelante, no eran más que armatostes de habitaciones enteras que funcionaban a base de válvulas y tubos de vacío. Estas máquinas estaban construidas y no programadas para cumplir una función específica, esto significaba que cada vez que tenía que cambiar de tarea se requerían semanas para diseñar y cambiar toda su estructura.Imagen del ENIAC, uno de los primeros ordenadores - U.S. Army Photo, Dominio público, EnlaceEn respuesta a esto el científico John Von Neumann ideó una arquitectura con una unidad de procesamiento central y una memoria. Esta última era la encargada de dar las instrucciones al procesador sobre cómo tenía que comportarse. El procesador mantiene una estructura modular, solo hay que reprogramarlo, no reconstruirlo.Componentes de la estructura Von NeumannCPU, siglas de Unidad de Procesamiento Central en inglés. Dirige el funcionamiento del ordenador y es el encargado de realizar las operaciones necesarias para obtener los datos que se solicitan.La Unidad Aritmético-Lógica, o ALU, realiza las operaciones de cálculo del ordenador. Por ejemplo las sumas, operaciones AND y OR, o comparaciones de valores.La UC, o Unidad de Control, hace de intermediaria entre la ALU y la memoria principal. Obtiene la operación de la memoria y los datos necesarios para ejecutarla, al finalizar devuelve el resultado a la memoria.Los registros almacenan temporalmente la información del proceso que se está realizando. Un ejemplo de registro es el \"registro acumulador\", este guarda los resultados temporales de una operación que se encuentra en curso en la ALU.La memoria principal almacena las instrucciones que debe ejecutar el procesador y los datos necesarios para realizarlas. Aunque es poco común escuchar este nombre, es otra forma de llamar a la memoria RAM de los ordenadores modernos.Los dispositivos de E/S, o entrada y salida, permiten la comunicación del ordenador con el exterior, usualmente con el usuario.Los buses (marcados como flechas en la ilustración) son los canales de comunicación entre los componentes del ordenador.Ciclo de instrucciónTeniendo en cuenta lo lioso que puede resultar el esquema (que parece un cajero automático) y las descripciones, vamos a explicar paso a paso, y de forma muy simple, cómo trabaja un procesador desde el momento en el que se inicia hasta el apagado.Leer la instrucción:La UC detecta cual es la instrucción a realizar y se la solicita a la memoria principal.La memoria principal transfiere la instrucción al registro.Si existe algún dato necesario para realizar la instrucción, también se envía al registro.Ejecutar la instrucción:La Unidad de Control envía la instrucción y los datos necesarios a la ALU.La ALU ejecuta la instrucción y obtiene el resultado.La UC envía el resultado a la memoria principal y lee cual es la siguiente instrucción, iniciando el ciclo de nuevo." }, { "title": "Como instalar Adobe Reader en GNU/Linux de forma nativa", "url": "/posts/como-instalar-adobe-reader-en-gnu-linux-de-forma-nativa/", "categories": "Misceláneo", "tags": "Adobe, ftp, instalar, libre, linux, okular, Wine", "date": "2020-08-14 13:52:25 +0200", "snippet": "La indiscutible fama de Adobe ha llevado a muchos a que alguna de sus herramientas sea imprescindible a la hora de trabajar en el ordenador. Ya sea con Adobe Photoshop o Adobe After Effects o el ma...", "content": "La indiscutible fama de Adobe ha llevado a muchos a que alguna de sus herramientas sea imprescindible a la hora de trabajar en el ordenador. Ya sea con Adobe Photoshop o Adobe After Effects o el maravilloso Adobe XD (solo lo he puesto porque me hace gracia el nombre).Aunque estas herramientas no están disponibles para GNU/Linux de forma nativa hay una, al menos, que sí lo está, aunque no sea algo muy comentado. Con unos sencillos pasos vamos a instalar Adobe Reader para Linux, esta aplicación nos permitirá visualizar PDFs y, aunque no tenga tantas funciones como su versión de Windows, sigue cumpliendo su función. Si se quiere usar la última versión siempre se puede optar por usar Wine y cruzar los dedos para que funcione.Obtención del .debComo siempre, evitaremos usar intermediarios y obtendremos el paquete de instalación directamente desde la página oficial de Adobe. Desde este enlace podrás obtener todas las versiones para Linux de Adobe Reader. El enlace es un directorio FTP, puedes abrirlo desde Archivos o desde un navegador, aunque algunos de estos estén eliminando ya su compatibilidad con el protocolo FTP.Si no puedes usar ninguno de estos métodos, aquí tienes directamente el comando que puedes utilizar para obtener la última versión disponible cuando se escribió el post:wget ftp://ftp.adobe.com/pub/adobe/reader/unix/9.x/9.5.5/enu/AdobeRdr9.5.5-1_i386linux_enu.debProceso de instalaciónAdobe Reader solo está disponible en 32 bits para Linux, así que haremos unos pasos extra. Primero instalaremos la arquitectura de 32 bits. Con el siguiente comando se realiza la instalación y se actualizan los repositorios al mismo tiempo.sudo dpkg --add-architecture i386 &amp;amp;&amp;amp; sudo apt-get updateTras esto, nos dirigimos al directorio donde hayamos descargado el programa y lo instalamos.sudo dpkg -i AdbeRdr9.5.5-1_i386linux_enu.debSolución de erroresLa instalación se detendrá por un fallo, le daremos la instrucción de continuar igualmente con el siguiente comando.sudo apt-get install -fAhora podremos ejecutar Adobe Reader con el comando acroread.Probablemente de fallo en las librerías, por lo que las instalaremos manualmente.sudo apt-file search libxml2.so.2sudo apt-get install libxml2:i386Tras esto ya podremos ejecutar Adobe Reader de nuevo, lo podemos hacer mediante comandos o encontrarlo en las aplicaciones de Ubuntu.&lt;/p&gt;Alternativas libres&lt;/h2&gt;Algunas funciones de la aplicación no funcionan y tiene un aspecto bastante antiguo. Aun así, la aplicación funciona a pesar de ser una versión descontinuada.Existen opciones de código libre más actualizadas disponibles. Entre ellas se encuentra Okular, el lector de PDFs de KDE." }, { "title": "Módem, router y punto de acceso. En qué se diferencian.", "url": "/posts/modem-router-y-punto-de-acceso-en-que-se-diferencian/", "categories": "Apuntes SMR, Servicios en Red", "tags": "dns, módem, punto de acceso, raspberry, router", "date": "2020-06-12 22:01:50 +0200", "snippet": "Es posible que muchos no conozcan el nombre real o técnico del aparatejo que les da Internet a sus hogares. Aunque suele ser conocido comúnmente como “router”, puede llegar el caso en el que tengam...", "content": "Es posible que muchos no conozcan el nombre real o técnico del aparatejo que les da Internet a sus hogares. Aunque suele ser conocido comúnmente como “router”, puede llegar el caso en el que tengamos que diferenciar un router de lo que realmente estamos usando. Es por ello que siempre va a venir bien conocer los distintos tipos de aparatos que nos podemos encontrar.MódemPuede que identifiquemos un módem como ese cacharro antiguo que se conectaba a la línea telefónica, hacía un ruido espantoso, y nos daba conexión a Internet siempre y cuando no descolgásemos el teléfono.Pues en parte sí, eso es un módem, pero hay otras cosas que lo son. Su definición es la del dispositivo encargado de la conversión de la señal a modo de que un ordenador pueda interpretarla. En resumidas cuentas es un conversor, y el encargado de ponernos en contacto con nuestro proveedor de Internet, ya sea mediante fibra óptica, cable coaxial o el anticuado ADSL.Módem ADSL. Se puede reconocer el conector telefónico y el Ethernet.RouterEl más conocido por la gente. Un router es el encargado de crear una red funcional y comunicar todos los dispositivos a esta. Un router, si se configura debidamente, también es capaz de comunicar dos redes locales entre sí.El router no solo incluye servicios, así como el DNS o el DHCP, también tiene la función NAT, conocida también como enmascaramiento de IP o traducción de direcciones. Esta función permite que nuestros dispositivos se conecten con la red pública (Internet por ejemplo) utilizando el router como intermediario, actuando como capa para que no se conozca la estructura de nuestra red local. También permite que se comparta una sola dirección IP pública para todos los dispositivos de la red local, ahorrando una cantidad considerable de IP’s, las cuales son un gasto de dinero elevado.Los routers también suelen tener incorporados varios puertos Ethernet, cumpliendo también la función de switch.Punto de accesoLos puntos de acceso inalámbricos (Wireless Access Point) son dispositivos que crean una red inalámbrica (Wi-Fi) para que los dispositivos se puedan conectar remotamente. Estos puntos gestionan también la encriptación inalámbrica a base de un nombre para la red (UUID) y una contraseña. El sistema actual de encriptación suele ser el WPA2.3 en 1Seguro que mientras leías todo este embrollo pensarías “el cacharro que tengo en mi casa hace todo eso, entonces, ¿cuál de todas las cosas es?”. La respuesta es simple, todas.Para que una red local al uso funcione a la perfección requiere de estos tres complementos. Un particular no va a comprar estas tres cosas para tener WiFi en casa, es por ello que las compañías suelen ofrecer (incluido en el contrato) un dispositivo 3 en 1. Este creará una red WiFi en el hogar para que se conecten todos los dispositivos usando el punto de acceso, gestionará la red y les pondrá en contacto con el exterior mediante con el router y le dará acceso a Internet con el módem.Estos dispositivos 3 en 1 suelen ser los que llamamos directamente “routers” y el que la gran mayoría de personas tienen en sus casas. Dependiendo de la compañía que se tenga contratada, será más laxa o menos a la hora de configurar tú mismo la red, añadiendo tu propio router para mayores gestiones o tu propio punto de acceso para ampliar la señal wifi.De izquierda a derecha podemos apreciar dos conectores coaxiales (módem), cuatro puertos Ethernet (router/switch) y una antena para la conexión innalámbrica (punto de acceso).En esta imagen podemos ver el 3 en 1 de mi operadora de internet, modificado para que solo actúe de módem. Mi router TP-Link que actua también como punto de acceso. Abajo mi Raspberry con un disco duro de 1TB como servidor en la nube." }, { "title": "Añadir un directorio al PATH", "url": "/posts/anadir-un-directorio-al-path/", "categories": "Apuntes SMR, Sistemas Operativos Monopuestos y en Red", "tags": "bash, linux, PATH, shell", "date": "2020-06-06 18:35:39 +0200", "snippet": "Hace poco un amigo ha tenido problemas con unos comandos que el sistema no le detectaba. El motivo era porque el directorio donde se encontraban no formaba parte del PATH del sistema. El PATH básic...", "content": "Hace poco un amigo ha tenido problemas con unos comandos que el sistema no le detectaba. El motivo era porque el directorio donde se encontraban no formaba parte del PATH del sistema. El PATH básicamente es una lista con los directorios donde se encuentran los comandos. Al escribir uno en el terminal, el sistema buscará el comando en estos directorios para poder ejecutarlo.Si el directorio del comando no se encuentra en el PATH habrá que escribir toda la ruta hasta este para ejecutarlo. Saber como añadir un directorio aquí será útil en caso de algún error, de crear nosotros algún comando u otras razones.Conocer nuestro shellPrimero necesitaremos conocer el shell que estamos utilizando, cada uno tiene un archivo distinto donde se almacena el PATH. Para conocerlo ejecutamos el siguiente comando:ps -p $$&lt;Este comando nos devolverá el shell que utiliza nuestro sistema, generalmente será bash así que en este post explicaremos cómo añadir un directorio al PATH si se usa bash o zsh, un shell alternativo muy utilizado.Acceder al archivo de configuraciónCada intérprete de comandos tendrá un archivo de configuración distinto, este estará oculto dentro de nuestro home. Accederemos mediante comandos usando el editor de texto nano:Para bash:nano ~/.bashrcPara zsh:nano ~/.zshrcAñadir directorioDentro del archivo en el que estemos añadiremos, sin importar cual de los dos shell sea, la siguiente línea en la parte superior:export PATH=directorio:$PATHSustituimos “directorio” por la ubicación de los comandos. Por ejemplo export PATH=/home/ockham/cmds/bin:$PATHTras guardar y salir del documento tendremos que cerrar sesión y volver a entrar, aunque si sigue dando problemas recomiendo reiniciar." }, { "title": "Qué es la dirección MAC", "url": "/posts/que-es-la-direccion-mac/", "categories": "Apuntes SMR, Servicios en Red, Sistemas Operativos Monopuestos y en Red", "tags": "Mac", "date": "2020-05-12 13:33:00 +0200", "snippet": "Es probable que muchos de hayamos oído hablar de las direcciones IP, incluso que sepamos para qué sirven, pero las direcciones MAC son algo más desconocidas aunque igual de necesarias. En esta entr...", "content": "Es probable que muchos de hayamos oído hablar de las direcciones IP, incluso que sepamos para qué sirven, pero las direcciones MAC son algo más desconocidas aunque igual de necesarias. En esta entrada no solo veremos qué es la dirección MAC sino también alguno de sus usos.Qué esLas siglas de la dirección MAC vienen de Media Access Control, aunque en español también se la conoce como dirección física, y su función básica radica en identificar una tarjeta de red de forma global. Para los que no hayan entendido nada básicamente es el número de pasaporte de la tarjeta de red de nuestro ordenador, un número único en todo el mundo.Este número es único y exclusivo para identificar tarjetas de red, puesto que son las encargadas de enviar y recibir información del exterior. Esto incluye las tarjetas de red integradas en las placas base (que suelen ser Ethernet), tarjetas Wi-Fi del ordenador o del móvil, tarjetas Bluetooth.En teoría, al ser parte de un componente físico, la dirección MAC no puede ser modificada. La realidad es muy distinta, Internet está repleto de tutoriales que muestran cómo hacerlo de una forma muy simple, incluso algunos dispositivos vienen con herramientas para cambiar la MAC. La finalidad de cambiarla siempre es ocultar un identificador del dispositivo, ya sea por privacidad o con malas intenciones.FuncionamientoEs un número hexadecimal de 48 bits separados en 6 bloques de 8 bits. Los primeros 3 bloques identifican al fabricante de la tarjeta, los 3 últimos es un número identificativo gestionado por la IEEE.Como una imagen vale más que mil palabras, vamos a insertar una imagen para explicar esto mejor.Esta estructura evita un descontrol al estar regularizado por la IEEE y permite identificar fácilmente algunos dispositivos por el identificador del fabricante.Diferencias entre dirección IP y dirección MACAmbas son direcciones de identificación a la hora de comunicarse con otros ordenadores. La diferencia principal es que la dirección IP puede variar mientras que la dirección MAC va a ser siempre la misma, esto nos da una serie de ventajas que veremos en otros apartados.Las direcciones IP tienen 4 grupos de dígitos decimales mientras que las direcciones físicas constan de 6 grupos de dígitos hexadecimales.Las direcciones MAC se pueden identificar con dos puntos o un guión. Las IP siempre van a separarse por un solo punto, solo incluirán dos puntos para indicar el puerto. Las direcciones IP pueden variar por distintas razones, una dirección MAC es permanente.Su uso en las redes localesPuede que un usuario al uso no le de mucha importancia pero una buena organización dentro de la red local (sea de empresa o la simple red Wi-Fi de un particular) es importante, tiene distintos beneficios como una mejora de seguridad.Dentro de mi propia red he usado la dirección MAC de algunos dispositivos para indicarle al router que les mantenga siempre la misma dirección IP. Esto me sirve para hacer instalaciones más fácilmente, por ejemplo, mantener la misma IP a una impresora hará que los ordenadores y móviles la detecten más fácilmente y evita que se desconfigure o duplique. También mantengo una IP estática en mi Raspberry con Nextcloud, para que el propio router pueda hacer una redirección de puertos y se pueda acceder desde fuera mediante un DDNS.El identificador de producto de las MAC y la IP de Nextcloud están censuradas por seguridad.El nombre del propietario del iPhone por razones obvias.La tabla de arriba corresponde a mi propio router, se puede observar como se ha asignado direcciones IP permanentes dependiendo de la MAC. En el momento de la captura mi impresora y otra Raspberry se encontraban apagadas, por ello no se puede ver cómo la impresora también tiene IP estática o como el identificador del fabricante de las dos Raspberrys coincide.Con respecto a los identificadores, se puede ver como el iPhone y el iPad no tienen el mismo ID de fabricante, esto se debe a que también se otorgan distintos identificadores al mismo fabricante. Todos los identificadores se pueden encontrar a través de la página de direcciones físicas.Su uso en los videojuegosNo es algo que suela verse a menudo pero las direcciones MAC también son usadas en los videojuegos en la lucha constante contra las trampas online. Es por eso que muchas compañías, a la hora de bannear a un jugador, pueden tomarlas siguientes consideraciones:Bloquear su cuenta puede ser innefectivo al poder crearse más de una.Restringir al jugador en base a su dirección IP es todavía más innefectivo e injusto, ya que una IP puede cambiar con el tiempo y podría bloquear a un jugador inocente. Dependiendo del tipo de red también podrían verse afectados varios jugadores.El bloqueo mediante la MAC no perjudica a otros usuarios pero es fácilmente evasivo con un clonado de MAC o simplemente comprando una tarjeta de red nueva. También generaría un problema en el supuesto caso de que el hacker vendiese su placa a otra persona, esta segunda heredaría el bloqueo.Por ello usualmente las compañías se mantienen aferradas al primer método, especialmente en juegos de pago. Al tener que crear otra cuenta, deben comprar de nuevo el juego, generando así ingresos extra a la compañía.Matizo que en ningún momento he indicado que el bloqueo mediante MAC sea el más común o efectivo, solo es una herramienta más que, si mal no recuerdo, ha causado polémica e compañías de videojuegos como Valve." }, { "title": "El papel de la informática en la lucha del COVID-19", "url": "/posts/el-papel-de-la-informatica-en-la-lucha-del-covid-19/", "categories": "Misceláneo", "tags": "coronavirus, covid, datos, pi, raspberry", "date": "2020-04-16 18:53:27 +0200", "snippet": "No quería hacer este post, quería dejar toda la situación y crisis sanitaria a un lado pero mira tú, al final lo he hecho.Dentro de toda la paralización a la que nos hemos visto sumidos a nivel mun...", "content": "No quería hacer este post, quería dejar toda la situación y crisis sanitaria a un lado pero mira tú, al final lo he hecho.Dentro de toda la paralización a la que nos hemos visto sumidos a nivel mundial se está sacando a la luz la importancia de algunos campos, colectivos y profesiones que no se creía tan imprescindibles. También se agravan los problemas que de por sí ya tenían, al menos en España, los sanitarios y todos los que les rodea.Entre toda esta marabunta de aislamiento social, distanciamiento, cuarentenas y trabajo a distancia las Tecnologías de la Información y Comunicación son más necesarias que nunca. Gracias al trabajo de décadas se ha conseguido que comunicarse de manera inmediata con tu amigo de la otra punta del globo terráqueo con un solo clic no sea tan imposible como hace 60 años. Y ahora, que la distancia es necesaria, ese trabajo se vuelve más importante.No solo es crear las herramientas sino también mantenerlas. Gracias al trabajo de “los raritos de los ordenadores” se puede trabajar desde casa y tener los mismos recursos que se usan en el trabajo (conectando el ordenador personal a una VPN o a un dominio de Active Directory por ejemplo); reunirte con tus compañeros de trabajo a través de Skype, Microsoft Teams o Discord.Pero todo esto es una ayuda de forma más o menos indirecta, ayuda a mantener la actividad en la empresa a distancia, en permitir que los familiares se vean entre ellos y facilitar que la información llegue a todo el mundo. Pero no se ve la ayuda activa que se está dando, salvando vidas.Salvando vidasPorque a parte de todo lo que acabamos de mencionar, hay que tener en cuenta que esos ahora tan preciados respiradores los están fabricando ingenieros utilizando componentes como nuestra querida Raspberry Zero, puedes ver el proyecto en GitHub.La escasez de mascarillas supone un peligro para el personal sanitario que no tiene como protegerse. Por suerte también se están utilizando impresoras 3D para crear pantallas protectoras. Se han formado comunidades a través de grupos de Telegram y equipos de desarrollo para organizarse y entregar de forma desinteresada medidas de protección al personal sanitario. También han habilitado una página web para que empresas puedan aportar, otros “makers” puedan apuntarse y gente que lo necesite reciba material sanitario. La página web de makers ha cerrado por obvias razones. Puedes ver cómo era desde Internet Archive.Ahora que se está aplanando la curva y algunos comercios pueden empezar a abrir de nuevo sus puertas hay que mantener un sistema para saber si puedes haber infectado o no a alguien, poder llevar un control. Esto se ha hecho en China, Corea del Sur y Taiwan, identificando a los ciudadanos y llevando un control de sus movimientos para saber quién ha podido estar en contacto con un infectado. En España el Gobierno está haciendo algo parecido, utilizando las antenas de los teléfonos móviles para conocer los movimientos de personas y detectar flujos sospechosos y concentraciones ilegales.Obviamente el sistema que utilizan vulnera totalmente nuestra privacidad y no solo eso, sino que al utilizar las antenas de telefonía nuestra ubicación es más imprecisa y las compañías telefónicas también tienen acceso a esos datos (aunque ellos siempre).Existe una solución muy popular, usando una aplicación móvil y que detecta cerca de quién hemos estado usando el Bluetooth de nuestro móvil, lo que lo hace un sistema mucho más efectivo. A demás nos mantiene en completo anonimato. Podría enrollarme mucho tratando de explicarlo, pero como una imagen vale más que mil palabras me he tomado la libertad de publicar un pequeño cómic explicativo de Nicky Case y traducido al español por la comunidad del Partido Interdimensional Pirata. Agradezco a ambos la posibilidad de publicarlo y haberlo liberado bajo licencia Creative Commons para hacer posible su difusión.       " }, { "title": "El arranque del sistema, medidas de seguridad y el GRUB.", "url": "/posts/el-arranque-del-sistema-medidas-de-seguridad-y-el-grub/", "categories": "Apuntes SMR, Seguridad Informática, Sistemas Operativos Monopuestos y en Red", "tags": "arranque, grub, linux, windows", "date": "2020-04-10 16:28:51 +0200", "snippet": "Seguro que todos los que estamos leyendo este post hemos tenido uno de esos ordenadores que al encenderlo soltaba un pitidito, o más de uno. Mi maravilloso ordenador de torre con Windows Vista siem...", "content": "Seguro que todos los que estamos leyendo este post hemos tenido uno de esos ordenadores que al encenderlo soltaba un pitidito, o más de uno. Mi maravilloso ordenador de torre con Windows Vista siempre soltaba dos al encenderse, y en aquella época yo era tan curioso que nunca me pregunté qué significaban, era feliz mientras el ordenador arrancase.Vamos a ver no solo qué significan esos pitidos sino todo el sistema que lo ejecuta y todo lo que ocurre entre que pulsas el botón de encender hasta que ves como arranca el sistema operativo.BIOSEl sistema básico de entrada y salida, BIOS por sus siglas en inglés, es un tipo de firmware incluido en todas las placas base el cual se pone en funcionamiento cuando uno inicia el ordenador. Usualmente también se conoce a la BIOS como Legacy, debido a que es un sistema antiguo y la UEFI lo ha sustituido casi completamente. La BIOS se encarga de detectar los componentes del ordenador, asegurarse que funcionan correctamente y buscar en los dispositivos de almacenamiento un gestor de arranque para darle todo el control del hardware al sistema operativo.Cuando encendemos el ordenador tenemos un pequeño periodo de tiempo en el que podemos acceder a la BIOS pulsando unas teclas concretas, estas dependen del fabricante de la placa base. Dentro de la BIOS tenemos varias posibles configuraciones, destacaremos algunas en este post, como por ejemplo el poder elegir la prioridad de dispositivos a la hora de buscar un sistema de arranque o la posibilidad de cambiar entre BIOS y UEFI.UEFILa interfaz de firmware extensible unificada, UEFI por sus siglas en inglés, apareció hace unos años para jubilar a la BIOS tras más de 45 años de leal servicio. La UEFI hace exactamente lo mismo que la BIOS, con ciertas mejoras y añadidos:Gestión más eficiente de la energía.Iniciar de forma más rápida.Admite particiones de más de 2TB.La posibilidad de gestionar los dispositivos PCIe.Gestión de fallos mejorada.Mejor interfaz gráfica, pudiendo usar el ratón.Actualizar su firmware desde Internet.Incluye Secure Boot, el cual se explicará más adelante.Qué es el POSTEl POST es conocido como auto-prueba de arranque, forma parte de las medidas de seguridad de la BIOS y se encarga de realizar pruebas a los dispositivos antes de ejecutar la BIOS para asegurarse que ninguno está dañado a nivel de software ni de hardware. Técnicamente, la placa base lanzará un pitido de confirmación cuando el POST haya terminado de realizar las pruebas pero en los ordenadores más modernos me estoy encontrando placas que no sueltan ningún pitido de confirmación, solo cuando hay fallos.Los pitidos también suenan para identificar fallos, pueden variar según el fabricante pero en general suelen significar lo mismo. Durante mi estancia en prácticas en el departamento de Devoluciones y Garantías lidiaba diariamente con componentes dañados, por lo que los pitidos de error del POST eran comunes, a continuación añado algunos de los pitidos de error más comunes y sus significados: Tonos Significado Tono ininterrumpido Fallo en el sistema de alimentación. 1 tono largo No detecta memoria RAM. 1 tono largo y 2 cortos Fallo en la tarjeta gráfica 3 tonos cortos RAM defectuosa. 5 tonos cortos Fallo en el procesador 10 tonos cortos Error en el CMOS. Secure BootEl Secure Boot es un sistema de seguridad de Microsoft para las BIOS que, como se puede deducir, favorece a los sistemas Windows. Su intención es evitar los Bootkits, un tipo de malware que toma el control del ordenador haciéndose pasar por un sistema operativo, bloqueando todo sistema operativo que no sea de “confianza”. De nuevo, como se puede deducir, los sistemas de “confianza” de Microsoft son sus propios sistemas operativos algún otro, pero se pueden contar con los dedos de una sola mano.Si se usa un sistema Windows es una buena idea mantener esta opción encendida, ya que da un plus de seguridad, pero si se va a instalar un GNU/Linux o un Dual Boot conviene desactivarlo para evitar problemas.Los gestores de arranque y el GRUBLos gestores de arranque sirven para que la BIOS detecte dónde se encuentran almacenados los sistemas operativos y pueda darles el control al terminar todos los procesos que se indican arriba. Se instalan junto al sistema operativo y sirve de intermediarios entre estos y las BIOS.Existen gestores de arranque para varios sistemas operativos. Windows tiene el suyo propio y puede hacer que se pueda elegir entre distintos Windows antes de arrancarlos, pero a penas soporta otros sistemas. Yo todavía no he visto un sistema Linux que sea soportado por este sistema.Por otro lado está el llamado GRUB, el gestor de arranque múltiple. Este gestor de arranque permite elegir entre distintos sistemas, instalados en distintos discos, sin importar cual sea. Desde versiones Windows, distribuciones basadas en Ubuntu, CentOS… lo que sea." }, { "title": "Cómo funcionan las versiones de Ubuntu. Qué son las versiones LTS", "url": "/posts/como-funcionan-las-versiones-de-ubuntu-que-son-las-versiones-lts/", "categories": "Sistemas Operativos Monopuestos y en Red", "tags": "linux, ubuntu, versión, windows, windows xp", "date": "2020-03-13 21:50:50 +0100", "snippet": "A medida que pasa el tiempo todo debe actualizarse, por mucho que nos duela el cambio es permanente e inevitable. Los sistemas operativos están cambiando constantemente ya sea con actualizaciones d...", "content": "A medida que pasa el tiempo todo debe actualizarse, por mucho que nos duela el cambio es permanente e inevitable. Los sistemas operativos están cambiando constantemente ya sea con actualizaciones de seguridad o con nuevas versiones. Aprovechando que se terminó el soporte de Windows 7 hace poco y mi reciente actualización a Kubuntu 19.10 voy a explicar como funcionan las actualizaciones de Ubuntu, esto incluye sus versiones con distinto entorno como Kubuntu, Lubuntu, Xubuntu y Ubuntu MATE.Cómo se nombran las versionesA diferencia de otros sistemas operativos o aplicaciones, las versiones de Ubuntu son periódicas siendo estas dos anuales, siempre en abril y octubre.Se distinguen numerándolas por el año y el mes de lanzamiento. Por ejemplo, la versión de Ubuntu de abril de 2016 se llama 16.04 y la de octubre del mismo año 16.10.A parte de la parte numérica tiene un nombre, el cual cambia en cada versión. Los nombres constan de dos partes, un adjetivo y un animal. La primera letra de cada parte siempre coincide, a demás cada versión avanza una letra en el abecedario. Para que se vea más claramente vamos a poner una tabla desde la versión de abril de 2016 hasta la de octubre de 2019. Version de Ubuntu Nombre de version 16.04 LTS Xenial 16.10 Yakkety 17.04 Zesty 17.10 Artful 18.04 LTS Bionic 18.10 Cosmic 19.04 Disco 19.10 Eoan Soporte de cada versiónTodos los sistemas tienen cierto tiempo de soporte, lo que se podría llamar una vida útil, en el que reciben actualizaciones de seguridad y los desarrolladores que están detrás del sistema dan apoyo y soluciones a los problemas de los usuarios. Pero los sistemas se quedan desfasados por el tiempo. Por muy buen sistema que fue en su momento nadie instalaría ahora mismo Windows XP al igual que nadie instalaría Ubuntu 6.10. Aunque ambos se puedan seguir descargando no tienen ninguna seguridad ni soportan las aplicaciones actuales; es más, el Internet Explorer de Windows XP ni siquiera soporta el sistema de comunicación de Internet actual, por lo que ni se podrá navegar por Internet.Las versiones de Ubuntu tienen un soporte de 9 meses, considerablemente menos que los 17 años de Windows XP y los 11 de Windows 7. Pero cada dos abriles, como podemos ver en la tabla de arriba, sacan lo que se llama versión LTS.Qué es una versión LTSTambién llamadas versiones de soporte a largo plazo (Long Term Support en inglés) salen en abril cada dos años, siendo las últimas versiones la 16.04 LTS y 18.04 LTS y la próxima será la 20.04 LTS. Estas versiones tienen un soporte en servidores de 10 años y en clientes 5 años.Solo con esto se puede ver que estas versiones son más seguras y recomiendo que se instalen siempre." }, { "title": "Actualizar la distribución de Ubuntu sin borrar datos", "url": "/posts/actualizar-la-distribucion-de-ubuntu-sin-borrar-datos/", "categories": "Misceláneo, Sistemas Operativos Monopuestos y en Red", "tags": "datos, distribución, distro, Kubuntu, ubuntu, versión", "date": "2020-02-11 16:41:33 +0100", "snippet": "Al igual que los sistemas Windows, las distribuciones de Ubuntu también tienen su periodo de vida útil. Cuando pasa este tiempo las versiones dejan de recibir soporte y actualizaciones de seguridad...", "content": "Al igual que los sistemas Windows, las distribuciones de Ubuntu también tienen su periodo de vida útil. Cuando pasa este tiempo las versiones dejan de recibir soporte y actualizaciones de seguridad por lo que se vuelven vulnerables a futuros ataques. Vamos a hablar no solo de cómo actualizar a la última versión de Ubuntu sino qué versión elegir.Qué versión de Ubuntu escogerUbuntu y todas sus variantes (así como Kubuntu o Lubuntu entre otras) tienen dos tipos de versiones. Las versiones estándar tienen una duración de 9 meses y las versiones extendidas tienen un soporte de 5 años.Por motivos obvios vamos a elegir las versiones de larga duración, estas son llamadas LTS y lanzan una cada dos años. En el momento de escribir este blog la última versión extendida es la de Ubuntu 18.04 LTS con soporte hasta 2023 y dentro de dos meses lanzarán la versión 20.04 LTS y tendrá soporte hasta 2025.Existen motivos para utilizar las versiones de corta duración, pondré mi caso como ejemplo. Mi ordenador portátil traía por defecto Kubuntu 18.04.2 LTS pero al cabo de varios meses quería personalizar profundamente su apariencia, para lo cual necesitaba una versión del framework Qt que mi sistema no tenía. La forma más fácil de solucionar esto era actualizar a Kubuntu 18.10, cuyo soporte terminó en julio de 2019 y yo, como buen incauto, aún lo tenía instalado.Siempre hay que fijarse cuando termina el soporte del sistema que vas a instalar, por ejemplo, el soporte de la versión 19.04 terminó el mes pasado por lo que hay que pasar a la siguiente, la 19.10. Obviamente también hay que mirar qué novedades ofrecen estas versiones, si son interesantes o compatibles con lo que se tiene instalado.Actualizar la versión de UbuntuVamos a buscar la aplicación llamada “Software Y Actualizaciones”, entraremos en la tercera pestaña estableceremos el “notificarme de una nueva versión de Ubuntu” del menú desplegable “Para cualquier nueva versión”.Tras esto abrimos el terminal y ejecutamos como súperusuario los siguientes comandos.sudo apt updateEs muy probable que esta herramienta ya esté descargada, ahora comprobaremos que instalaremos la última versión, aunque no sea de larga duración. Para ello escribimos el siguiente comando.sudo nano /etc/update-manager/release-upgradesEsto nos llevará a un archivo de configuración, en la última línea tenemos que comprobar que pone Prompt=normal, de no ser así lo cambiaríamos.Ahora toca cambiar todos los repositorios a las versiones que queramos. Cada versión de Ubuntu tiene un nombre, a continuación pondré los de las últimas versiones. Version de Ubuntu Nombre de version 16.04 LTS Xenial 16.10 Yakkety 17.04 Zesty 17.10 Artful 18.04 LTS Bionic 18.10 Cosmic 19.04 Disco 19.10 Eoan Ahora escribiremos el siguiente comando sustituyendo “antiguo” por la versión actual (bionic en mi caso) y “nuevo” por la versión nueva (eoan en mi caso). Importante sin mayúsculas.sudo sed -i 's/antiguo/nuevo/g' /etc/apt/sources.listAhora actualizaremos los repositorios para tener los adecuados. Como tiene que descargar todos los paquetes nuevos es probable que tarde bastante.sudo apt update &amp;&amp; sudo apt upgrade -sUna vez ha terminado ejecutamos el comando de actualización de distribución.sudo apt dist-upgradeTras la actualizaciónEs posible que el ordenador se reinicie alguna vez durante la actualización, es normal. Al finalizar ejecutaremos un comando para eliminar los paquetes obsoletos.sudo apt autoremove &amp;&amp; sudo apt cleanSi tenemos algún problema leeremos en la respuesta de la terminal qué ocurre, es posible que se pueda solucionar ejecutando el siguiente comando.sudo apt --fix-broken installUna vez actualizados todos los paquetes y reiniciado el ordenador podremos ver que ya tenemos la nueva distribución instalada en nuestro ordenador sin haber perdido las aplicaciones ni los archivos." }, { "title": "¿Por qué Windows marca los discos con menos capacidad que los fabricantes?", "url": "/posts/por-que-windows-marca-los-discos-con-menos-capacidad-que-los-fabricantes/", "categories": "Sistemas Operativos Monopuestos y en Red", "tags": "binario, bytes, decimal, discos, linux, windows, windows 10", "date": "2020-01-15 17:09:08 +0100", "snippet": "Esta entrada va dedicada a un amigo mío que compró recientemente un disco duro de 960GB y se sorprendió al ver que Windows le marcaba mucho menos. Aunque compres un disco de 1TB te marcará aproxima...", "content": "Esta entrada va dedicada a un amigo mío que compró recientemente un disco duro de 960GB y se sorprendió al ver que Windows le marcaba mucho menos. Aunque compres un disco de 1TB te marcará aproximadamente 931GB y cuanta más capacidad compres más gigabytes se perderán. Vamos a explicar por qué ocurre esto y quién tiene la culpa. Porque sí, hay un culpable, o varios.Unidades de medida en informáticaPrimero de todo hablemos de como se mide la capacidad de datos en informática. De manera física, toda la información que se transporta por un ordenador funciona con corrientes eléctricas, de forma que todo funciona a base de hay corriente y no hay corriente, esto se interpreta como 0 y 1. Los datos tanto en los discos duros y los discos de estado sólido son de 0 y 1, cada número de estos se llama bit y, la unidad básica de medida se compone de 8 bits y se llama byte.A partir de aquí tenemos las unidades más comunes y que se suelen escuchar más a menudo entre la gente. Vamos a ver una tabla con las unidades de medida del sistema internacional. Nombre Simbolo Cantidad de bytes Kilobyte KB 103 Megabyte MB 106 Gigabyte GB 109 Terabyte GB 1012 Petabyte PB 1015 Exabyte EB 1018 Zettabyte ZB 1021 Yottabyte YB 1024 Estas unidades ascienden exponencialmente en base 10, igual que lo hacen los metros, los gramos. Ahora bien, realmente en informática somos algo especiales. Los metros tienen base 10 porque se usan 10 cifras para generar los números, empezando por el 0 y terminando con el 9, cuando se llega a este número se añade una nueva cifra, las decenas, y así sucesivamente. En informática, como hemos dicho antes, se usa únicamente el 0 y el 1, el código binario, por lo que de forma práctica la unidad de medida tendría que ser en base 2. Esta unidad es la usada y apoyada por el IEEE y vamos a mostrar una tabla con este sistema. Nombre Simbolo Cantidad de bytes Kibibyte KiB 210 Mebibyte MiB 220 Gibibyte GiB 230 Tebibyte GiB 240 Pebibyte PiB 250 Exbibyte EiB 260 Zebibyte ZiB 270 Yobibyte YiB 280 De esta forma podemos ver como en lugar de cambiar la unidad cada 1000 bytes lo hacemos cada 210=1024 bytes. Así vemos que 1TiB son 1024GiB, 1 GiB son 1024MiB, 1MiB son 1024KiB… Con esto lo tenemos todo explicado.Como juegan los fabricantes con estoAquí vamos a ver como y por qué los fabricantes juegan con estas unidades de medida. Primero de todo vamos a usar las tablas de arriba para sacar cuantos bytes son la “misma” unidad de medida. Vamos a utilizar 1 mega en sistema decimal y binario.\\[1MB = 1^6B = 1.000.000 bytes\\]\\[1MiB = 2^{20}B = 1.048.576 bytes\\]Podemos apreciar como 1MiB tiene ligeramente más capacidad que 1MB. También podemos ver como, a medida que aumenta la capacidad, esta diferencia aumenta. Entonces aquí viene el tema de los fabricantes.Un fabricante, como empresa que es, intenta abaratar gasto, una buena forma que tienen de hacerlo es fabricar sus componentes usando el sistema decimal y no el binario, principalmente porque tienen que crear menos capacidad, lo cual es más barato y simple.El problema viene cuando sabemos que el sistema práctico en la informática es el binario, y anunciar que venden un disco de, por ejemplo, 931GiB no vende tanto que decir que lo venden de 1TB. Ambas afirmaciones son correctas, pero con la última parece que sea más almacenamiento por lo que venden más. Es una estrategia de marketing que llevan usando desde siempre.Como actúa Windows ante estoTodos sabemos que Windows es el sistema operativo más usado a nivel de usuario y esto ayuda (o dificulta) a que los usuarios comprendan la informática. En este caso lo empeora ya que Windows muestra el sistema binario como si fuera decimal. Esto quiere decir que un disco de 1TB o 931GiB lo marcará como 931GB, lo cual es completamente erróneo. Desconozco completamente el motivo por el que Windows muestra esto así pero hace ver como si los fabricantes fueran unos mentirosos lo cual es mentira, solo cambian el sistema de medida para hacerlo más comercial.He leído muchos artículos que dicen que las empresas de unidades de almacenamiento nos mienten de esta forma, a demás utilizan el sistema de Windows para demostrarlo, decir que el sistema internacional está en binario. Curiosamente ninguno de los artículos mencionan el sistema de la IEEE ni la diferencia de ambos sistemas.Como actúa GNU/Linux ante estoAhora viene un punto interesante y olvidado, la posición de Linux ante toda esta absurda batalla de marketing y de tipos de sistemas de medida. Y la respuesta es la indiferencia. Linux no entra en estas batallas y como sistema desarrollado por informáticos competentes cumple todas las normas y muestra las cosas como son. Dependiendo de las herramientas y el sistema que se utilice puede que use el sistema internacional o el de la IEEE siendo este último el más común.Gestor de particiones de KDE mostrando un disco de 1TB como su capacidad real en binario" }, { "title": "Vincular calendario de Office 365 a Google Calendar con Microsoft Power Automate", "url": "/posts/vincular-calendario-de-office-365-a-google-calendar-con-microsoft-power-automate/", "categories": "Misceláneo", "tags": "calendar, google, microsoft, office 365", "date": "2019-12-23 14:28:19 +0100", "snippet": "Lista de todas las aplicaciones online que incluye.Seguro que no soy el único que tiene cuentas de distintas compañías como Google y Microsoft. En mi caso utilizo la primera para uso personal y la ...", "content": "Lista de todas las aplicaciones online que incluye.Seguro que no soy el único que tiene cuentas de distintas compañías como Google y Microsoft. En mi caso utilizo la primera para uso personal y la segunda es la que me ha ofrecido una institución de voluntariado de la que soy muy activo. El calendario que uso es solo uno, para que no se solapen los eventos, pero desde hace poco el equipo al que pertenezco está usando el calendario de Outlook para coordinarse así que se me ha ocurrido la idea de vincularlos automáticamente. Aviso que usamos la edición empresarial de Office 365, no se como funcionan las otras ediciones ni si tienen todos estos complementos incluidos.Conozcamos las herramientasOffice 365 es un paquete de herramientas y ofimática creado por Microsoft. En este se incluyen los programas como Excel, PowerPoint, Word, Outlook, etcétera. En mi caso también incluye OneDrive, OneNote, Yammer, Forms, Planner y, la que nos interesa ahora mismo, Power Automate. Esta potentísima herramienta permite automatizar tareas y darle instrucciones al resto del Office 365 para que funcione de forma más inteligente. Existen plantillas para facilitarnos la tarea.Cómo va a funcionarEl “flujo” (así lo llama Microsoft) se mantendrá a la espera eternamente, su mecha de ignición será la creación o aceptación de un evento en el calendario de Outlook. En ese momento, el flujo se pondrá en contacto con nuestra cuenta de Google y creará el mismo evento en este. Parece fácil pero el sistema de Google Calendar ha cambiado hace un tiempo por lo que las plantillas que aparecen en Microsoft están desfasadas, y ya no hay soporte para este tipo de herramientas. De manera que no usaremos plantilla y tendremos que escribir dos líneas de código para arreglar lo que Microsoft no quiere arreglar.Creación del eventoDentro de Power Automate accederemos a la pestaña de Crear y seleccionaremos la opción de flujo automatizado. Aquí pondremos el nombre que queramos y el desencadenante, el cual será la creación de un evento en Outlook.Al darle a siguiente entraremos en el panel del lujo, seleccionaremos el calendario de Outlook donde creamos los eventos, usualmente se llama simplemente “Calendario”. Ahora añadimos desde el botón “Nuevo paso” lo que queremos que ocurra tras crear el desencadenante.Al buscar la palabra “Google” nos aparecerá ya la opción de crear un evento en Google Calendar.Seleccionaremos nuestra cuenta de Google (es posible que antes nos haya pedido iniciar sesión para poder dar permisos a Power Automate).A continuación hay que indicar la hora de inicio y de finalización del evento. Si ponemos que utilice la hora de Outlook en el calendario nos dará error al ejecutar el flujo debido a que Google y Microsoft no utilizan el mismo sistema para marcar las horas. Para ello tenemos que escribir un código que haga la conversión.Para la hora de inicio escribimos el siguiente código:convertToUtc(triggerOutputs()?['body/start'], 'GMT Standard Time')Para la hora de finalización escribimos el siguiente código:convertToUtc(triggerOutputs()?['body/end'], 'GMT Standard Time')Para todo lo demás podemos personalizarlo como queramos. Recomiendo marcar que el título y la descripción sean la misma. Una vez terminan el flujo se debe hacer una comprobación creando un evento en Outlook e iniciar el flujo. A partir de ahora todos los eventos que se creen o que se acepten en Outlook se añadirán a Google Calendar automáticamente." }, { "title": "Probando Franz. La aplicación para tener todos tus chats en uno.", "url": "/posts/probando-franz-la-aplicacion-para-tener-todos-tus-chats-en-uno/", "categories": "Misceláneo", "tags": "Arch Linux, facebook, franz, KDE, linux, Manjaro, messenger, telegram, ubuntu, windows", "date": "2019-10-30 07:32:23 +0100", "snippet": " Solo el cliente de Franz es libre y las funcionalidades están restringidas para la cuenta premium.Todo empezó cuando me di cuenta que, por algún motivo, el cliente de Telegram Desktop para Linux ...", "content": " Solo el cliente de Franz es libre y las funcionalidades están restringidas para la cuenta premium.Todo empezó cuando me di cuenta que, por algún motivo, el cliente de Telegram Desktop para Linux no permite usar dos cuentas mientras que el de Windows y el de teléfonos sí. A demás tengo varias cuentas de Facebook y de WhatsApp y también quería tener acceso rápido a esos chats.Descubrí rápidamente Franz, una aplicación que se dedicaba exclusivamente a eso. Pero me daba mala espina, quería una que fuera código abierto para tener mayor seguridad y, para mi sorpresa, Franz está bajo licencia Apache 2.0.InstalaciónWindowsLa instalación de Franz en Windows no es nada fuera de lo común. Solo hay que entrar en el apartado de descargas de su página y descargar para Windows, como cualquier otro programa.LinuxFranz no tiene PPA oficial, lo que quiere decir que no te lo puedes descargar usando comandos. Para hacerlo tienes que descargartelo desde la web. Como usuario de Windows no me hace mucha gracia y se que existen repositorios no oficiales pero al ser eso, no oficiales, lo más seguro es hacerlo desde la web. Para Debian, Ubuntu y derivados se descarga el .deb y para otros sistemas como Arch Linux, Manjaro, CentOs, etc se usará el paquete .appimage No se como funcionan exactamente estos paquetes pero me da a mi que no se actualizan.En Kubuntu suelo usar Discover para instalar este tipo de paquetes. Una vez descargado se le da clic derecho y se selecciona Discover, se selecciona instalar y ya esta todo hecho.Una vez instalado se crea una cuenta, tras esto la aplicación te informa que su forma de ganar dinero es un pago opcional.Servicios disponiblesA continuación puedes añadir servicios de mensajería. Chatwork, Cisco Spark, Facebook Pages, FastMail, Flowdock, Gadu-Gadu, GitHub, Gitter, Glowing Bear, Google Allo, Google Voice, Grape, GroupMe, HipChat, ICQ, Idobata, IRCCloud, mailbox.org, Mattermost, Microsoft Kaizala, Microsoft Teams, MySMS, Pocket de Opera, Roundcube, SteamChat, WhatsApp, Messenger, Slack, Gmail, Skype, Telegram, Google Calendar, Discord, Hangouts, Linkedin, Trello, Office 365 y Google Keep. Y un laaargo etcétera que me da pereza escribir. También se puede conectar una web personalizada, el sistema de mensajes de Android y lo que supongo que son los mensajes directos de Twitter (Tweetdeck). Puedes ver todos los servicios en este enlace.PrecioExiste la posibilidad de usar Franz con una cuenta gratuita, en esta se pueden usar tres servicios a elegir y contiene anuncios. Luego existen suscripciones de pago. La versión personal, de 2,99€ al mes y no tiene anuncios y se pueden usar seis servicios. La versión profesional y Enterprise tienen la opción de usar servicios ilimitados y este último se puede integrar con Active Directory." }, { "title": "Probando juegos en Manjaro KDE", "url": "/posts/probando-juegos-en-manjaro-kde/", "categories": "Misceláneo", "tags": "Arch Linux, drivers, juegos, KDE, Kubuntu, linux, Manjaro, Minecraft, Plasma, Proton, ProtonDB, shooter, Steam, Valve, windows", "date": "2019-10-26 12:36:42 +0200", "snippet": " ACTUALIZACIÓN: Se ha publicado una entrada más reciente con fecha a 5/3/22. Pulse aquí para visitarla.En la sección Sobre mí he comentado los ordenadores que tengo ahora mismo, entre estos se enc...", "content": " ACTUALIZACIÓN: Se ha publicado una entrada más reciente con fecha a 5/3/22. Pulse aquí para visitarla.En la sección Sobre mí he comentado los ordenadores que tengo ahora mismo, entre estos se encuentra un ordenador de torre montado a piezas con Windows 10. Desde hace un tiempo he querido cambiarme el sistema operativo a uno Linux y me he decantado por instalar Manjaro KDE.¿Por qué Manjaro?Tenía decidido que quería instalarme un sistema operativo con KDE Plasma, mi primera opción durante mucho tiempo ha sido Kubuntu, el mismo sistema que tengo en mi ordenador portátil, pero desde hace unos días (en concreto desde la liberación de Plasma 5.17) me ha entrado el gusanillo de probar un sistema rolling release, en concreto Manjaro. Si no lo conoces, Manjaro es un sistema operativo GNU/Linux basado en Arch Linux. Con este último sistema he tenido mis pequeñas peleas, me ha dado problemas de instalación en otras ocasiones así que decidí por su derivado, el cual he escuchado que es más “friendly”.&lt;/p&gt; ATUALIZACIÓN: El 8/7/21 documenté una instalación de ArchLinux con encriptación. Pulse aquí para visitarla.Preparándolo para jugarLa gracia de mi ordenador de torre es poder usarlo para jugar y viendo los problemas de drivers gráficos que tuve durante mi primera instalación de Kubuntu, en un portátil Acer Aspire E5, no tenía ganas de pasar por lo mismo. Todos sabemos la controversia que hay entre Linux y los videojuegos. Steam ha ayudado mucho a que los juegos se puedan jugar en Linux y le estamos muy agradecidos. Por eso, antes de instalar Manjaro definitivamente en mi PC de sobremesa, he decidido hacer una prueba.He cogido un disco de 320GB que había desmontado de mi ordenador antiguo antes de deprenderme de él (con Windows Vista y en mi posesión desde 2007) tras 8 años de leal servicio y lo he montado en el actual, y así poder probar el sistema con todos los recursos reales del ordenador, con doble monitor y la gráfica Nvidia.He decidido instalar tres juegos. Euro Truck Simulator 2, un simulador de camiones al que suelo jugar mucho y está disponible en Linux de forma nativa; The Division, es un shooter en tercera persona con una calidad gráfica suficiente para exprimir mi tarjeta gráfica y Rising Storm 2 Vietnam, últimamente mi FPS favorito, con un motor gráfico de hace bastantes años pero puramente multijugador.Para saber el rendimiento en estos juegos usaré el marcador de FPS de Steam y la misma calidad gráfica en todas las pruebas.Instalando Euro Truck Simulator 2 y The Division. Los otros dos paquetes se instalan automáticamente para la compatibilidad con Linux.Jugando en WindowsEuro Truck Simulator 2Este juego no es que sea muy exigente gráficamente hablando, por lo que lo tengo a Ultra con algunas opciones en Alto. He realizado un trayecto pequeño, a penas 135km con lluvia y me mantenía unos 75 FPS estables. Nada mal.The DivisionHacía mucho que no jugaba a este shooter, me trae buenos recuerdos a pesar de los terriblemente repetitivo que es. He completado algunas misiones llenas de disparos, explosiones, etcétera y ha estado entre los 50 y los 60 FPS en una calidad Alta.Rising Storm 2 VietnamComo he dicho antes no se requiere un gran equipo para este juego, tiene un motor gráfico de hace años y no es que tenga una calidad extrema, lo juego a Ultra. Ya sea en tiroteos o en medio del fuego de artillería se ha mantenido a 60 FPS estables.Jugando con drivers de código abiertoEuro Truck Simulator 2Me he puesto la misma configuración que jugando en Windows, todo en Alto y con lluvia. He de decir que es el recorrido de 15km más largo que he hecho, mantenía unos 9 FPS estables y alguna vez tenía un pico que llegaba a 15. Imposible jugar así.The DivisionAl inciar el juego ha marcado que estaba instalando DirectX de Windows. Tras esto ha estado varios minutos sin hacer nada y entonces ha aparecido la pantalla de inicio de sesión de Uplay, la plataforma de juegos de Ubisoft.Luego, al ver que no hacía nada reinicié el ordenador, volví a iniciar el juego y me fui a hacer otras cosas. Al volver sorpresa sorpresa tenía este mensaje en mi pantalla y todas las animaciones de Plasma estaban bugeadas.Tras este mensaje ya no ocurre nada. He mandado reporte a ProtonDB.Rising Storm 2 VietnamQué puedo decir. Tras tres intentos de iniciarlo no ocurre nada. Era de esperar teniendo en cuenta que aún en Windows su inicio suele ser lento y en alguna ocasión da problemas, se bugea o no responde.Jugando con drivers propietariosEuro Truck Simulator 2Con el temor de la prueba con los drivers abiertos aún en la sangre he dado una vuelta a una ciudad bajo la lluvia y con calidad Alta y el juego nunca bajaba de los 60 FPS iba de maravilla.The DivisionEl juego ha arrancado correctamente, como si nada, y he podido jugar dos misiones pequeñas. Se mantiene en los 60 FPS con pequeños picos de 40 FPS en calidad Alta. Poniendo el juego en la calidad automática me mantiene los 60 FPS y baja de vez en cuando durante los tiroteos pero aún se puede jugar sin molestias.Rising Storm 2 VietnamEl juego ha tardado un poco en iniciar (como en Windows) pero al menos lo ha hecho. Ya el menú tenía lagazos importantes que cambiando el juego a “Ventana sin bordes” se soluciona. También el personaje que aparece en la portada estaba sin un buen procesado, le faltaban los ojos y los camuflajes no están bien. Tiene un problema grave y es que no es compatible con el sistema anti-hack, esto quiere decir que en menos de 5 minutos de haber empezado a jugar te echará de la partida. Para solucionar esto, la única opción que hay hasta que lo arreglen, es entrar en servidores que no tengan activado el sistema anti trampas, una gran minoría.ConclusiónMe entristece decirlo pero no usaría drivers libres para jugar, ni pensarlo, al menos de momento. Los drivers propietarios sí que permiten jugar de una forma placentera, no tanto como en Windows, pero sigue estando muy optimizado. Proton ha ayudado mucho a la instalación de los juegos y, repito, Valve ha hecho un gran trabajo con la plataforma Steam para darle juegos a Linux.Aún hay cosas que pulir, los sistemas anti-trampas no están preparados para usarlos en Linux ni con Proton, por lo que los multijugadores que usan esto quedan descartados por ahora, una pena.Aún quiero probar UBOAT, un juego indie en early access que estuve más de un año esperando y no me ha decepcionado, es algo inestable y tiene bugs, será un buen exámen para Proton. También, fuera de Steam, quiero probar Minecraft, ponerle shaders y paquetes de texturas." }, { "title": "Thunderbird. Gestor de correos electrónicos abierto.", "url": "/posts/thunderbird-gestor-de-correos-electronicos-abierto/", "categories": "Misceláneo", "tags": "google, KDE, KMail, linux, Mozilla, OAuth, Outlook, thunderbird, Windows", "date": "2019-10-19 14:57:49 +0200", "snippet": "He de ser sincero. Este artículo lo creé a consta del de KMail. Quise usar un gestor de correo electrónico libre y pensé que el que viene incluido en KDE sería buena idea. Los problemas que tiene c...", "content": "He de ser sincero. Este artículo lo creé a consta del de KMail. Quise usar un gestor de correo electrónico libre y pensé que el que viene incluido en KDE sería buena idea. Los problemas que tiene con Gmail como muestra el artículo no son los únicos, durante mi corta experiencia con este gestor he sufrido de congelamientos constantes (incluso en otras TTY, he tenido que volver a hacerlo todo varias veces y hasta un par de reinicios. Otros compañeros han tenido también problemas similares. Simplemente horrible.Aproveché esto para probar Mozilla Thunderbird, el gestor de correos electrónicos más conocido, de código abierto, bajo licencia libre de Mozilla (compatible con GPL) y disponible en Linux, Windows y Mac. A demás es el que se usa en la empresa en la que estoy haciendo prácticas.InstalaciónComo siempre, antes de todo, vamos a ver como se instala este programa.WindowsPuedes instalar la última versión para Windows a través de este enlace. Si no te descarga la versión con tu idioma o la versión correcta puedes buscarla aquí. La opción personalizada no es muy larga ni complicada por lo que recomiendo usar esta.UbuntuEmpezamos con la actualización de los repositorios seguido de la descarga del programa y del paquete en español.sudo apt-get update -ysudo apt-get install thunderbird thunderbird-locale-es-es -yTras esto ya se puede abrir el programa tranquilamente.Configurar una cuenta de correo electrónicoSi es la primera vez que abrimos el programa nos saldrá una ventana emergente donde crearemos la cuenta. Para cualquier otra circunstancia podremos hacer clic derecho en el panel lateral izquierdo y seleccionar “Configuración”. En la parte de abajo podremos ver un desplegable “Operaciones sobre la cuenta” donde escogemos “Añadir cuenta de correo”.Las opciones de inicio de sesión son más simples y están más automatizadas.Al darle a “Continuar” Thunderbird intentará encontrar la configuración del servidor de correo seleccionado. Por la experiencia que he tenido he visto que tiene muchas más listas automáticas de las que esperaba, incluido el servidor de correo de mi instituto, en este caso ya está todo hecho. Si no encuentra el servidor primero revisa que esté todo bien escrito, luego coloca manualmente el servidor entrante y saliente o consulta en Internet o al encargado IT los servidores.Si la cuenta es de Gmail o está bajo gestión de G-Suite se abrirá una pestaña solicitando el acceso.Y con esto la cuenta ya está creada, notoriamente más fácil que en KMail.A diferencia de KMail, el envío de correos, las firmas y la gestión de mensajes en general es mucho más intuitivo y no considero que se necesite más información de la que ya se ha dado. Escribe un comentario si no crees que sea así.Thunderbird no es como Gmail o Outlook, no forma parte de un servicio de correo así que tiene la misma compatibilidad con todos y puede gestionarlos por igual.En la imagen de arriba podemos ver distintos servicios de correos que se gestionan a través de este cliente. Gmail es muy conocido y sencillo de agregar, como hemos visto arriba se abre una ventana para autorizar a través de la OAuth de Google. Después podemos ver una cuenta de correo de este dominio, por razones obvias no detecta qué configuración usa, cambiando dos opciones tal y como aparecen en el hosting podremos acceder sin problema. La tercera opción es de Vivaldi, un navegador web que usa su propia cuenta de correo electrónico para las copias de seguridad, este servicio de correo no es tan conocido pero aun así Thunderbird lo configura automáticamente. El siguiente es una cuenta privada gestionada por G-suite, también la ha detectado automáticamente." }, { "title": "Vincular una cuenta de Gmail en KMail", "url": "/posts/vincular-una-cuenta-de-gmail-en-kmail/", "categories": "Misceláneo", "tags": "correo, distro, electrónico, Gmail, google, imap, KDE, KMail, Kontact, linux, Plasma, pop", "date": "2019-10-13 16:12:33 +0200", "snippet": " Al momento de escribir este artículo, la aplicación KMail tiene varios reportes de inestabilidad. Aunque los pasos siguientes se han probado, es recomendable cambiar a otro cliente de correo como...", "content": " Al momento de escribir este artículo, la aplicación KMail tiene varios reportes de inestabilidad. Aunque los pasos siguientes se han probado, es recomendable cambiar a otro cliente de correo como Mozilla Thunderbird o Evolution.KMail es uno de los tantos componentes de Kontact, un grupo de aplicaciones para la gestión del día a día bajo licencia GPL. KMail está preinstalado en las distribuciones con KDE pero se puede utilizar en cualquier distribución. Pero esta aplicación tiene un problemilla, y es que suele dar errores al intentar conectar tu cuenta de Gmail así que vamos a ponernos manos a la obra para saber como solucionarlo y poder acceder a nuestro correo sin usar el navegador.Instalación de KMailMejor primero vemos como instalar esta suite. Si usas KDE casi seguro que ya la tienes y puedas saltarte este paso. Si no lo tienes la instalación es sencilla, y recuerda que puede instalarse en cualquier distro. Primero de todo actualizaremos los repositorios y luego instalaremos.sudo apt updatesudo apt install kmailUna vez finalizado ya podremos encontrar KMail en nuestro sistema.Configuraciones previas con GmailVamos a preparar el sistema para permitir el acceso de KMail a nuestra cuenta de correo de Google, para ello solo tenemos que entrar en este enlace y permitir el acceso a aplicaciones inseguras. Es importante mantener esta opción siempre habilitada o todo se irá al traste.Vincular cuenta de Gmail a KMailEs la hora del momento decisivo. Es muy importante que se haga siguiendo estos pasos y no desde la opción de “Añadir cuenta…”, esta crea una configuración errónea de la cuenta que lleva a un error. Nos iremos a Preferencias y “Configuración de KMail…” y en “Recepción” le daremos a la opción de “Añadir cuenta de correo” dentro de la opción de añadir.Escribiremos nuestro nombre, dirección de correo electrónico de Google y contraseña de este. Importante desmarcar las preferencias del proveedor.La siguiente ventana es una opción de seguridad preguntando si se desea usar un par de claves para cifrar los mensajes. Esto también puede usarse para firmar, lo mejor es conseguir alguna firma de una entidad certificadora ya que los certificados autofirmados no tienen mucha validez, en el artículo sobre los certificados SSL se habla más de este tema.En la siguiente ventana se tiene que seleccionar el tipo de cuenta de correo. Los usados siempre suelen ser IMAP y POP3, de los cuales siempre recomiendo el uso del IMAP en cualquier circunstancia. A continuación se tiene que poner el servidor de correo entrante y saliente, donde pondremos lo siguiente.Al darle a siguiente se empezará a configurar la cuenta y se abrirá una ventana de carga que, al ponerla en pantalla completa, se verá que es una página de inicio de sesión de Google solicitada por KDE. Tras poner nuestra contraseña y permitir el acceso se terminará la configuración y podremos acceder a nuestros correos desde la aplicación.En caso de error…Desde hace un tiempo al poner la contraseña en el último paso sale un mensaje de Google diciendo que no ha confirmado la aplicación. En este caso terminaremos la configuración como si todo hubiera ido correctamente. Volveremos a irnos a la configuración del KMail y en el apartado de “Recepción” seleccionaremos nuestra cuenta y le daremos a “Modificar”. En la opción de servidor IMAP pondremos “imap.googlemail.com”. En el apartado de “Envío” haremos lo mismo y pondremos “smtp.googlemail.com”.Con esto KMail ya debería poder acceder a Gmail y empezará a descargar los correos.Dependiendo de la cantidad de correos KMail tardará más o menos en terminar la sincronización. Esta cuenta la tengo desde 2013 y la sincronización tardó entre 3 y 4 horas.ResultadosDe esta forma he comprobado que se ha podido mandar y recibir con éxito correos de Gmail por KMail por lo que todo ha salido bien. A continuación muestro pruebas del envío y la llegada de los correos." }, { "title": "Qué es el CLI y el GUI", "url": "/posts/que-es-el-cli-y-el-gui/", "categories": "Sistemas Operativos Monopuestos y en Red", "tags": "cli, comandos, consola, gui, instalar, terminal, tty, wayland, windows, windows 2016 server, xorg", "date": "2019-10-09 01:40:14 +0200", "snippet": "Recuerdo que la primera vez que escuché CLI y GUI solo podía deducir que podía significar y tuve que buscarlo en Internet. Ambos son conceptos usados frecuentemente en la informática hablando sobre...", "content": "Recuerdo que la primera vez que escuché CLI y GUI solo podía deducir que podía significar y tuve que buscarlo en Internet. Ambos son conceptos usados frecuentemente en la informática hablando sobre aplicaciones y sistemas operativos.Cuadro de instalación de Windows 2016 Server, donde mencionan el GUI como opción instalable.Qué es el CLIViene del inglés Command Line Interface, significa interfaz por línea de comandos. Es el entorno ese feucho de pantalla negra y letras blancas, dónde todo el uso se debe realizar mediante órdenes de comandos y edición de ficheros de configuración. Aquí no se puede utilizar el ratón.Esta interfaz se encuentra en todos los sistemas operativos y encima de esta se instala una interfaz gráfica (GUI). En Ubuntu por ejemplo la versión CLI es la usada en servidores y sobre estas se instala un entorno de escritorio (Mate, KDE, Cinnamon, Unity…) para las versiones de escritorio.Consola TTYEn los sistemas Linux existen diferentes “ventanas” que se pueden utilizar simultáneamente. Estas ventanas van del 1 al 7 y se puede acceder a estos pulsando Ctrl + Alt + Fx siendo la “x” el número deseado. Una de estas TTY, normalmente la TTY1, se usará por el sistema para cargar el entorno gráfico.Al cambiar de TTY estará en línea de comandos y se podrá usar así o, usando determinados comandos, iniciar el entorno gráfico. También, al no tener nada que ver ni enlazado ningún TTY con otro, aunque inicies sesión con una cuenta en el entorno gráfico puedes usar otro usuario en otro TTY y acceder a este en cualquier momento con la combinación de teclas.Qué es el GUISon las siglas de Graphical User Interface o interfaz gráfica de usuario, esto viene significando que se usa un motor gráfico (Xorg, Wayland) para generar una forma de comunicación con el ordenador con la que se le pueda dar órdenes sin el uso de texto (por decirlo de la forma más coloquial pero correcta que se me ocurre). Vamos, que es el entorno donde se utiliza un ratón, ventanas y esas cosas bonitas.CLI emulado dentro del GUIEl GUI tiene aplicaciones como el terminal (distintos nombres según el entorno y la distribución) o el símbolo del sistema (Windows) en las que se interactúa como un CLI, y se podría decir que es como un enlace a este, pero no es más que un emulador, no es un terminal de comandos real, se puede usar el ratón para moverse por el historial o seleccionar secciones de texto." }, { "title": "Qué es un RAID", "url": "/posts/que-es-un-raid/", "categories": "Seguridad Informática", "tags": "hardware, raid", "date": "2019-10-01 16:37:50 +0200", "snippet": "Siempre pueden pasar fallos, errores mecánicos a causa del paso del tiempo o algún defecto o accidente. Si esto se produce en un disco duro podríamos llegar a perder toda la información que se guar...", "content": "Siempre pueden pasar fallos, errores mecánicos a causa del paso del tiempo o algún defecto o accidente. Si esto se produce en un disco duro podríamos llegar a perder toda la información que se guarda en él. Da igual se sea una empresa o un particular, hay veces que vale la pena tener una doble copia de algo, y no me refiero a una copia de seguridad de Windows en caso de haber tocado algo que no se debía, hablo de una copia de un disco enterito. Da igual las copias de seguridad que tengamos, siempre puede haber un pico de tensión eléctrica y fundirnos el disco (aunque para evitar esto están los SAI).Los RAID o grupo redundante de discos independientes es un sistema de almacenamiento de datos que gestiona varios discos para que guarden la información de una forma específica de manera que si se peta uno la información se puede recuperar. Y si te preguntas “¿Y que pasa si se inunda todo o hay un terremoto y se va todo a la mierda?” lo primero de todo buena pregunta, lo segundo: en ese caso tiene que haber un CPD de respaldo a varios kilómetros de distancia.Ahora bien, existen varios tipos de RAID y varias formas de gestionar los discos, empecemos por esto último.Niveles de RAIDRAID 0Este RAID no sirve para asegurar la información, pero sigue siendo un RAID. Se encarga de guardar la información en ambos discos como si de uno se tratase. El sistema los interpreta como uno solo y si uno de ellos se estropea la información del segundo estará incompleta y no servirá. Este RAID se utiliza para enviar la información el doble de rápido (en teoría), ya que son dos discos los que están mandando o guardando los datos a la vez, pero no mejora la seguridad, en todo caso la empeora porque al haber dos discos las posibilidades de fallo se duplican.RAID 1También llamado RAID espejo. Es muy básico y, como su nombre indica, guarda la misma información en ambos discos. Esto hace que si uno deja de funcionar se pueda consultar perfectamente el otro, pero como contra tiene la redundancia y es que al guardarse todo por duplicado la capacidad de un disco no se aprovecha.En estos discos la velocidad de escritura es la misma (en teoría) ya que graban los mismos datos al mismo tiempo pero aumenta la velocidad de lectura, ya que se puede leer el bloque A1 de un disco y el A2 del segundo.RAID 4 y 5Se que me he saltado muchos pero vamos a los importantes. En el RAID 4 se utiliza como mínimo 3 discos, la información se guarda en dos de ellos como un RAID 0 y el otro se dedica exclusivamente a la paridad. El RAID 5 funciona igual que el RAID 4, su única diferencia es que no hay un disco exclusivo para la paridad, esta se guarda intercalada entre todos los discos.Qué es la paridadLa paridad es una forma simple de realizar una recuperación de los datos. Para explicarlo de una forma sencilla y no matar neuronas leyendo el artículo de Wikipedia usaremos la imagen del RAID 4 que tenemos arriba. Haremos que cada bloque sea un número y calcularemos la paridad para el cuarto disco.La paridad se calcula con la suma de todos los bloques siendo la paridad de este bloque el resultado de la operación. Para comprobar su efectividad vamos a formatear el disco 2. El sistema, para saber cual es el contenido que corresponde a este disco, tendrá que hacer una ecuación usando la paridad y los otros discos.En el caso del RAID 5 funciona exactamente igual.RAID 10Esta es una combinación entre el RAID 1 y el RAID 0 llamado división de espejos. Este RAID necesita un mínimo de 4 discos, dos grupos de dos en RAID 1 y unidos entre ellos en un RAID 0. Esto puede llevar a una implosión cerebral así que mejor ver la imagen para entenderlo.Estos RAID son buenos para datos de gran valor, porque resiste el fallo de un disco por cada grupo de RAID 1 bajando mucho la posibilidad de pérdida de los datos. A demás es un sistema relativamente rápido porque no se tiene que calcular ninguna paridad.Existen infinidad de niveles de RAID, estos son los más comunes. El resto de RAIDs suelen estar basados en los aquí mencionados o son muy enrevesados o ineficaces. Dependiendo también de las características y lo que se necesite se escogerá uno u otro, cada situación es distinta.Tipos de RAIDHay distintas formas de conectar un RAID, cada uno con unas características distintas. Algunas son para servidores en rack pero vamos a hablar de tres que pueden usarse en pymes y particulares.Por hardwareSe conecta al ordenador una extensión dedicada. El sistema operativo detecta solo un disco y lo trata como tal y es esta extensión la encargada de gestionar y dividir la información del RAID entre los dos discos.Esta extensión PCIe tiene dos puertos SATA para conectar los dos discos aquí en lugar de a la placa base.Por softwareEste es un RAID un poco pocho. El ordenador no detecta ni gestiona el RAID, de esto se encarga el sistema operativo tras la instalación. En los sistemas Windows se puede entrar en el administrador de discos y en un par de clics tenerlo funcionando. Recuerdo que en Linux se podía configurar con el comando mdadm. El problema es que depende del SO, gasta recursos de este y como cambies el sistema o sea este el que falle tendrás dos discos algo inútiles y será más tedioso arreglarlo.RAID falsoSe llama así porque simula ser un RAID por hardware siendo realmente por software. El firmware que lo gestiona se encuentra incorporado en la placa base del ordenador, lo que significa que no nos tenemos que preocupar por los posibles problemas con el sistema operativo y no gasta recursos del sistema, pero sí de la placa, cosa que se podría aprovechar para otra cosa (que se note que mi favorito es el de hardware). Pero que no os confunda el nombre, sigue siendo mejor que el que funciona por software." }, { "title": "Qué es el DDNS", "url": "/posts/que-es-el-ddns/", "categories": "Servicios en Red", "tags": "cg-nat, ddns, dns", "date": "2019-09-30 09:00:15 +0200", "snippet": "Si mi memoria no me falla, en 2018 se acabaron todas las direcciones IPv4 públicas que se podían dar, esto significa que tampoco se podía otorgar una misma IP a un único dispositivo, lo que hacían ...", "content": "Si mi memoria no me falla, en 2018 se acabaron todas las direcciones IPv4 públicas que se podían dar, esto significa que tampoco se podía otorgar una misma IP a un único dispositivo, lo que hacían las operadoras de Internet era que, cuando se desconectaba un router, se liberaba su IP pública y se le otorgaba a otro. Esto también aumenta el precio de las direcciones IPv4 públicas y se especula sobre su uso.¿Como afecta esto al DNS?El DNS se encarga de vincular un FQDN (visualmente es parecido a una URL) con la dirección IP del servidor correspondiente. Esto facilita enórmemente la tarea de aprendernos las direcciones de acceso a nuestros servicios favoritos. Por ejemplo, si quieremos entrar en Wikipedia, nos es más fácil recordar wikipedia.org que 91.198.174.192.El problema llega cuando la dirección 91.198.174.192 no es fija y la van cambiando cada cierto tiempo, en ese caso nos tendríamos que acordar cada vez de un número distinto y el DNS no serviría porque la IP vinculada a wikipedia.org ahora es posible que lleve a la IP de Google.Para solucionar esto está el DDNS o DNS Dinámico, este servicio actualiza automáticamente la dirección IP vinculada cuando detecta que esta cambia, de forma que mantiene la misma URL sin problemas.UsosEsto es muy efectivo a la hora de ahorrar direcciones IP. Los hostings pueden ir jugando con estas sin que los visitantes de las páginas se percaten de ello. Para uso doméstico es una maravilla. Si tienes un servidor en casa y quieres que que se pueda acceder desde fuera necesitarás un DDNS porque la compañía con la que tengas contratado Internet va a ir cambiando tu IP (a no ser que tenga CG-NAT, en ese caso no podrás usar un DDNS).Servicio gratuitoPara tener un DDNS se necesita un hosting que gestione únicamente esto. Puedes tener el servidor en casa y usar no-ip para tener un ddns con un subdominio algo feo, como *.ddns.net o *.zapto.org. Lo único que se tiene que hacer es confirmar cada 30 días que se sigue usando este servicio haciendo click a un enlace que se mandará por correo electrónico." }, { "title": "Instalar un sistema operativo a la Raspberry", "url": "/posts/instalar-un-sistema-operativo-a-la-raspberry/", "categories": "Apuntes SMR", "tags": "instalar, kali linux, kodi, nextcloud, noobs, pi, raspberry, raspbian, retropie, sistema operativo, tutorialx", "date": "2019-09-26 18:36:01 +0200", "snippet": "Se conoce que la Raspberry es una herramienta excepcional para empezar en la informática, ya sea en programación, robótica… O incluso administración, porque si tienes pocos recursos puedes empezar ...", "content": "Se conoce que la Raspberry es una herramienta excepcional para empezar en la informática, ya sea en programación, robótica… O incluso administración, porque si tienes pocos recursos puedes empezar a conocer los servicios, su funcionamiento y aplicarlos en tu casa gastando muy poco. Por ejemplo, puedes usar una Raspberry como servidor Samba para compartir recursos entre todos los ordenadores y todas las cuentas de la casa, como fotos. Es importante que sepamos bien que sistema operativo instalar en la Raspberry para sacarle el máximo provecho.Qué necesitamosCuando vas a comprar una Raspberry hay que fijarse bien en qué se compra, muchas veces es simplemente la placa y nada más, ni cargador ni nada, entonces es importante comprar un pack donde incluya el siguiente material mínimo o comprarlo por separado.Placa base. La propia Raspberry. Se debería mirar qué modelo comprar, según presupuesto y proyecto.Cable de alimentación. Usan un voltaje distinto a los cables comunes por lo que hay que estar atento, mejor comprar uno original. La Raspberry Pi 4 usa un USB-C, el resto un Micro-USB.Tarjeta MicroSD. Es la memoria principal de la Raspberry, donde estará el sistema. Puedes escoger el tamaño que quieras, luego puedes poner un USB para aumentar la memoria.Periféricos de entrada. Importante mínimo un teclado por USB, para introducir las instrucciones en terminal o navegar por la interfaz si conoces los atajos, mejor poner también un ratón si vas a usar entorno gráfico.Periféricos de salida. Tal vez no hagan falta tras configurarlo todo pero como mínimo en el primer inicio es lo mejor. También hay pantallas táctiles.Que sistema elegimosAquí viene un asunto importante. Dependiendo de para qué vayamos a usar nuestra Raspberry instalaremos un sistema u otro. Se tendrá que buscar cual es el que más se acopla a las necesidades pero aquí voy a dejar algunos de mis recomendados.RaspbianEs el sistema oficial de la Raspberry, una versión adaptada de Debian. Actualmente está en su versión Buster (Debian 10) y es el único sistema oficial para la Raspberry Pi.Cuenta con una versión Lite, la cual es solo línea de comandos, para servidores. Y Desktop, con un escritorio y programas básicos como navegador, reproductor y su propio Minecraft.Página oficial de descargaKali LinuxOtra distro basada en Debian. Es muy conocida por tener una infinidad de programas de monitorización de redes y hackeo. Tiene una versión ARM apta para Raspberry, la cual puede ser un buen kit de hackeo.A mi parecer el mejor modelo para usarlo es la Raspberry Pi 4.Página oficial de descargaKodiEs un centro multimedia de código libre. Se puede usar para añadir contenido a una TV antigua, sirviendo como almacenamiento de películas que guardes. Siempre ha habido mucha controversia por las extensiones de terceros que tiene, las cuales piratean series y canales de televisión.Página oficial de descargaRetroPiMuy conocida por los melancólicos, aunque nunca me ha picado la curiosidad de probarlo. Por lo que sé incluye una buena cantidad de emuladores de 8 y 16 bits como SuperNintendo. Se pueden comprar carcasas de consolas y kits que incluyen mandos o una palanca de juegos.Página oficial de descargaNextcloud PiEs una versión adaptada de Nextcloud a ARM. Es un sistema utilizado como servidor en la nube. Se puede usar dentro de una red LAN o configurar para acceder desde el exterior. Tiene herramientas de visualización de PDF, ofimática en línea, etiquetas, cuotas de disco, envío de correos automáticos… lo que se necesite para crear un servicio en la nube completo.Página oficial de descargaComo instalar el sistema operativoPara instalar cualquier sistema necesitaremos poner la tarjeta SD en un ordenador y, obviamente, tener descargado el sistema que queramos. Se usará una herramienta para “quemar” el sistema en la SD distinta a la usada para quemar CDs. Personalmente utilizo el programa Balena Etcher en Ubuntu y Rufus en Windows, ambos código libre y licencia Apache 2.0 y GPL 3 respectivamente.Los pasos son sencillos e intuitivos.Con Rufus solo se necesita indicar el dispositivo donde se quiere flashear el sistema operativo, seleccionar el fichero de este y listo. Es, junto a Etcher, el programa más rápido en hacerlo que he visto.Etcher está disponible para Windows, Linux y Mac. Tiene una interfaz muy agradable y en tres pasos lo hace todo. Las ISOs de Windows suelen dar fallos con este programa.Tras instalar el sistema solo se conecta la microSD en su ranura y se conecta todo lo que se necesite, siendo el cable de alimentación lo último en conectar.NOOBS nos facilita la vidaA pesar de su nombre (siglas de New Out Of the Box Software, Nuevo Software Listo para Usar en inglés) es una herramienta muy útil y más sencilla de usar que las otras.Por decirlo de alguna forma es un instalador de sistemas operativos.  Existen dos versiones de NOOBS. La primera permite instalar Raspbian y LibreELEC sin conexión a internet y el resto de sistemas disponibles los puede instalar si se conecta la Raspberry a Internet, la versión Lite necesita conexión para instalar todo.Al descargar NOOBS no hay que flashear la SD, simplemente arrastras los archivos descomprimidos a la tarjeta y la conectas a la Raspberry. Entonces nos aparecerá un menú donde podremos elegir los sistemas a instalar (sí, pueden ser varios en Dual Boot). Se instalarán solos y elegiremos con cual iniciar por primera vez.Ya está todo listo para comenzar a usar la Raspberry." }, { "title": "Creando el blog", "url": "/posts/creando-el-blog/", "categories": "Misceláneo", "tags": "let's encrypt, siteground, ssl, wordpress", "date": "2019-09-21 07:01:05 +0200", "snippet": "Que mejor forma de empezar que mostrando mis vivencias al crear mi primera página web con hosting y con Wordpress.Desde hacía un tiempo que tenía algunos hostings en la mira, pero solo para recomen...", "content": "Que mejor forma de empezar que mostrando mis vivencias al crear mi primera página web con hosting y con Wordpress.Desde hacía un tiempo que tenía algunos hostings en la mira, pero solo para recomendar a un amigo. Después, tras varios días buscando recomendaciones y comparando servicios y ofertas me decanté por Sitegrounds. Con lo desconfiado que soy buscaba ir a lo seguro, nada de chollos ni anuncios por Internet y esto lo recomendaban en todos lados y había visto otras páginas web con este hosting.¿Por qué me decanté por Sitegrounds?Principalmente por lo que ya he comentado. he visto que páginas importantes este sitio y que lo recomiende el propio Wordpress es más que suficiente. A demás, me aseguré que el hosting permitiera el uso de Let’s Encrypt como medida SSL, y es que tiene hasta su propio instalador.Cuesta aproximadamente 4’77€ al mes (3’95€ que dice la página web más IVA) e incluye el dominio por un año, cuentas de correo ilimitadas, subdominios ilimitados, transferencia mensual ilimitada y 10GB de espacio en el disco.Problema con los .esHace meses ayudé a un amigo con la compra de un dominio usando otro hosting, IONOS para ser exactos. Cuando compró el dominio yo estaba delante para verlo y en un minuto ya estaba registrado en who.is. Entonces me preguntaba ¿Por qué el mío no está? ¿Por qué han pasado dos horas y sigo sin poder acceder?. La respuesta está en la administración española. Esta te hace pasar por unos trámites (en este caso a la empresa de hosting) antes de empezar con la difusión DNS. Esto yo no lo sabía, así que he estado dos días mordiéndome las uñas esperando que no sea un fallo y que sea algo normal. Hasta contacté con el servicio técnico.Durante ese tiempo intentaba entrar al servidor directamente mediante a IP del servidor, pero claro, estaba configurado para ser usado mediante el DNS y habían enlaces y herramientas que no me funcionaban. Lo solucioné cambiando la configuración de la red de mi ordenador forzando las peticiones DNS a los servidores de Siteground.De esta forma se solicita primero las peticiones DNS al servidor de Siteground, por lo que podría ver mi página web, y luego al DNS de Google, que me garantiza acceso al resto de Internet.El día 19 de septiembre de 2019 fue cuando vi por primera vez el blog sin tener que forzar nada, estaba todo listo y solté un buen suspiro de tranquilidad.ConstrucciónEra mi primera vez en Wordpress así que todo lo de buscar una plantilla, editarla y eso no era algo a lo que estaba acostumbrado. Por suerte, el funcionamiento de las entradas y las categorías me parecen muy similar a las de Joomla!, por lo que solo tengo que recordar ese horrible mes en el que estuve haciendo una página con ese CMS para un trabajo de clase y todo irá genial.La página todavía está muy verde y le falta mucho diseño (ni si quiera tiene aún favicon) pero la experiencia me ha dicho que eso no se debe hacer ahora, mejor poco a poco mientras la página va creciendo.Mientras tanto le he puesto un certificado SSL Wildcard de Let’s Encrypt, como en mi servidor Nextcloud, y unos pocos vectores SVG, sacados de una biblioteca libre y de la galería de iconos del tema por defecto de KDE Plasma, Breeze. Estos iconos cuentan todos con licencia GNU.También soy un desastre con las combinaciones de colores así que he usado una herramienta llamada Coolors para buscar alguna combinación que me guste.Buscaré más adelante tutoriales sobre Wordpress, que se que tiene mucho más potencial. También para las cookies analíticas, plugins, SEO, etc." } ]
